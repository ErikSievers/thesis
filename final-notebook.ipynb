{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file looks at producing example images\n",
    "\n",
    "Let's try to sharpen the images or look at the surrounding area of each pixel to highlight areas that may have an issue. Then let's look at\n",
    "trying to quantify the noise in each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from copy import copy\n",
    "from matplotlib import cm, colors\n",
    "import cv2\n",
    "\n",
    "objectwidth = 83\n",
    "objectheight = 122\n",
    "xspacing = 133\n",
    "yspacing = 270\n",
    "xstart = 293\n",
    "ystart = 268\n",
    "xend = 1730\n",
    "yend = 1770\n",
    "powderthickness = 80\n",
    "endlayer = 187\n",
    "\n",
    "paths = pathlib.Path('./OT data 80 um/int').glob('*.tif')\n",
    "paths_sorted = [x for x in paths]\n",
    "paths_sorted.sort()\n",
    "integrals = np.array([np.array(plt.imread(path)) for path in paths_sorted])[0:endlayer]\n",
    "\n",
    "objectinfo = pd.read_csv('Parameters.csv', names=[\"Object\", \"P\", \"S\", \"H\", \"Porosity\", \"Label\"])\n",
    "objectinfo.insert(1, \"VED\", objectinfo.P * 1000/(objectinfo.S * objectinfo.H * powderthickness))\n",
    "objectCoordinates = [[x, x+objectwidth, y, y+objectheight] for y in reversed(range(\n",
    "    ystart, yend, objectheight + yspacing)) for x in range(xstart, xend, xspacing + objectwidth)]\n",
    "coorddf = pd.DataFrame(objectCoordinates, columns=['xstart', 'xend', 'ystart', 'yend'])\n",
    "objectinfo = coorddf.join(objectinfo)\n",
    "\n",
    "del coorddf\n",
    "del objectCoordinates\n",
    "del paths_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets sharpen the image and then filter out all background pixels and set them to nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweaking parameter settings\n",
    "emptyRatio = 47\n",
    "sharpening = ['direct', 'diagonal']\n",
    "neighbourhood = ['grid', 'euclidean']\n",
    "windowsize = range(1, 7)\n",
    "type = ['scatter', 'moran', 'spatstat']\n",
    "buckets = range(30, 151, 30)\n",
    "#bucket-lower-limit?\n",
    "histnormalise = ('none', 'column', 'row')\n",
    "k = range(2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Preprocessing (sharpening and background filtering)\n",
    "def preprocess(integrals, sharpening, objectinfo, windowSize):\n",
    "    sharpeningKernel = np.array([   [-1, -1,  -1],\n",
    "                                    [-1,  9,  -1],\n",
    "                                    [ -1, -1,  -1]\n",
    "    ]) if sharpening == 'diagonal' else np.array([  [0, -1,  0],\n",
    "                                                    [-1, 5, -1],\n",
    "                                                    [0, -1,  0]])\n",
    "    sharpened = np.array([cv2.filter2D(src=image, ddepth=-1, kernel=sharpeningKernel) for image in integrals])\n",
    "# Sharpening is done\n",
    "    filtered = np.full(np.shape(integrals), np.nan)\n",
    "    for index, object in objectinfo.sort_values(by=['VED']).iterrows():\n",
    "        if type == 'scatter':\n",
    "            xs = np.array(sharpened[:, object.ystart:object.yend, object.xstart:object.xend], copy=True, dtype=np.float32)\n",
    "            sum = np.sum(xs, axis=0)\n",
    "            limit = np.percentile(sum, emptyRatio)\n",
    "            filter = sum >= limit\n",
    "            (endLayer, _, _) = sharpened.shape\n",
    "            filter = np.repeat([filter], endLayer, 0)\n",
    "            xs[~filter] = np.nan\n",
    "            filtered[:, object.ystart:object.yend, object.xstart:object.xend] = xs\n",
    "        elif type == 'moran':\n",
    "            xs = sharpened[:, object.ystart:object.yend, object.xstart:object.xend]\n",
    "            sum = np.sum(xs, axis=0)\n",
    "            limit = np.percentile(sum, emptyRatio)\n",
    "            filter = sum >= limit\n",
    "            (endLayer, _, _) = sharpened.shape\n",
    "            filter = np.repeat([filter], endLayer, 0)\n",
    "            avg = np.mean(xs, where=filter)\n",
    "            stddev = np.std(xs, where=filter)\n",
    "            xs = (xs - avg) / avg\n",
    "            xs[~filter] = np.nan\n",
    "            filtered[:, object.ystart:object.yend, object.xstart:object.xend] = xs\n",
    "        elif type == 'spatstat':\n",
    "            # Implement later\n",
    "            print(\"nyi\")\n",
    "    return sharpened\n",
    "\n",
    "def neighbourhood(sharpened, neighbourhood, windowSize):\n",
    "    neighbourkernel = np.array(\n",
    "        [[1, 1, 1],\n",
    "         [1, 1, 1],\n",
    "         [1, 1, 1]]\n",
    "    )/9 if neighbourhood == 'grid' else np.array(\n",
    "        [[1, 2,  1],\n",
    "        [2, 4, 2],\n",
    "        [1, 2,  1]])/16\n",
    "    flatNeighbourhood = np.array([cv2.filter2D(src=layer, ddepth=-1, kernel=neighbourkernel) for layer in sharpened])\n",
    "    (endLayer, _, _) = flatNeighbourhood.shape\n",
    "    neighbourhoodValues = np.array([\n",
    "        np.sum(flatNeighbourhood[layerIndex-windowSize:layerIndex], axis=0)/windowSize\n",
    "        for layerIndex in range(windowSize, endLayer)\n",
    "    ])\n",
    "    return neighbourhoodValues\n",
    "\n",
    "def encode(sharpened, objectinfo, neighbourhoodValues, windowSize, type, buckets, histnormalise):\n",
    "    offset = windowSize // 2\n",
    "    (endLayer, _, _) = sharpened.shape\n",
    "    # 1 -> 0\n",
    "    # 2 -> 1\n",
    "    # 3 -> 1\n",
    "\n",
    "    if type == 'spatstat':\n",
    "        print(\"nyi\")\n",
    "    else:\n",
    "        outliervalues = np.full(np.shape(neighbourhoodValues), np.nan)\n",
    "        for index, object in objectinfo.iterrows():\n",
    "            if object.Label == \"KH\":\n",
    "                continue\n",
    "            xs = sharpened[offset:endLayer-windowSize+offset+1, object.ystart:object.yend, object.xstart:object.xend]\n",
    "            ys = neighbourhoodValues[:, object.ystart:object.yend, object.xstart:object.xend]\n",
    "            filter = np.logical_and(np.isfinite(xs), np.isfinite(ys))\n",
    "            line = np.polyfit(ys[filter].flatten(), xs[filter].flatten(), 1)\n",
    "            p = np.poly1d(line)\n",
    "            outliervalues[:, object.ystart:object.yend, object.xstart:object.xend] = xs - p(ys)\n",
    "        minval = np.min(outliervalues)\n",
    "        maxval = np.max(outliervalues)\n",
    "        for index, object in objectinfo.iterrows():\n",
    "            if object.Label == \"KH\":\n",
    "                continue\n",
    "            xs = neighbourhoodValues[:, object.ystart:object.yend, object.xstart:object.xend]\n",
    "            filter = np.isfinite(xs)\n",
    "            label = object.Label\n",
    "            hist, _ = np.histogram(xs[filter], buckets=buckets, range=(minval, maxval))\n",
    "            if init == False:\n",
    "                X = np.array([hist])\n",
    "                Y = np.array([0 if label == 'GOOD' else 1])\n",
    "                init = True\n",
    "            else:\n",
    "                X = np.append(X, np.array([hist]), 0)\n",
    "                Y = np.append(Y, np.array([0 if label == 'GOOD' else 1]), 0)\n",
    "        \n",
    "        if (histnormalise == 'column'):\n",
    "            X = preprocessing.normalize(X, axis=0)\n",
    "        elif (histnormalise == 'row'):\n",
    "            X = preprocessing.normalize(X, axis=1)\n",
    "    return X, Y\n",
    "\n",
    "def classify(X, Y, type, buckets, histnormalise, k):\n",
    "loo = LeaveOneOut()\n",
    "for n_neighbors in range(2,5):\n",
    "    for weights in [\"uniform\", \"distance\"]:\n",
    "        print(\"Neighbours \" + str(n_neighbors) + \" weights \" + weights)\n",
    "        clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "        scores = cross_val_score(clf, X, Y, scoring=\"accuracy\", cv=loo.split(X))\n",
    "        print(scores)\n",
    "        print(\"%0.2f accuracy\" % (scores.mean()))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('thesis-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b582782fd74adb665333939d2eb8c9995c52902e0db289bedb880e3a83e2d4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
