{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file looks at producing example images\n",
    "\n",
    "Let's try to sharpen the images or look at the surrounding area of each pixel to highlight areas that may have an issue. Then let's look at\n",
    "trying to quantify the noise in each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from copy import copy\n",
    "from matplotlib import cm, colors\n",
    "import cv2\n",
    "\n",
    "emptyRatio = 47\n",
    "objectwidth = 83\n",
    "objectheight = 122\n",
    "xspacing = 133\n",
    "yspacing = 270\n",
    "xstart = 293\n",
    "ystart = 268\n",
    "xend = 1730\n",
    "yend = 1770\n",
    "powderthickness = 80\n",
    "endlayer = 187\n",
    "objectsplit = 4\n",
    "layersPerObject = endlayer // objectsplit\n",
    "testEnd = endlayer - layersPerObject\n",
    "\n",
    "paths = pathlib.Path('./OT data 80 um/int').glob('*.tif')\n",
    "paths_sorted = [x for x in paths]\n",
    "paths_sorted.sort()\n",
    "integrals = np.array([np.array(plt.imread(path)) for path in paths_sorted])[0:testEnd]\n",
    "testintegrals = np.array([np.array(plt.imread(path)) for path in paths_sorted])[testEnd:endlayer]\n",
    "\n",
    "objectinfo = pd.read_csv('Parameters.csv', names=[\"Object\", \"P\", \"S\", \"H\", \"Porosity\", \"Label\"])\n",
    "objectinfo.insert(1, \"VED\", objectinfo.P * 1000/(objectinfo.S * objectinfo.H * powderthickness))\n",
    "objectCoordinates = [[x, x+objectwidth, y, y+objectheight] for y in reversed(range(\n",
    "    ystart, yend, objectheight + yspacing)) for x in range(xstart, xend, xspacing + objectwidth)]\n",
    "coorddf = pd.DataFrame(objectCoordinates, columns=['xstart', 'xend', 'ystart', 'yend'])\n",
    "objectinfo = coorddf.join(objectinfo)\n",
    "zs = [objectinfo.copy().assign(zstart=z, zend=z+layersPerObject) for z in range(0, testEnd-layersPerObject, layersPerObject)]\n",
    "\n",
    "testobjectinfo = objectinfo.copy().assign(zstart=0, zend=layersPerObject+1)\n",
    "objectinfo = pd.concat(zs)\n",
    "\n",
    "del coorddf\n",
    "del objectCoordinates\n",
    "del paths_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors, metrics\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Preprocessing (sharpening and background filtering)\n",
    "def preprocess(integrals, objectinfo, type, sharpening,  windowSize):\n",
    "    sharpeningKernel = np.array([   [-1, -1,  -1],\n",
    "                                    [-1,  9,  -1],\n",
    "                                    [ -1, -1,  -1]\n",
    "    ]) if sharpening == 'diagonal' else np.array([  [0, -1,  0],\n",
    "                                                    [-1, 5, -1],\n",
    "                                                    [0, -1,  0]])\n",
    "    sharpened = np.array([cv2.filter2D(src=image, ddepth=-1, kernel=sharpeningKernel) for image in integrals])\n",
    "# Sharpening is done\n",
    "    filtered = np.full(np.shape(integrals), np.nan)\n",
    "    for index, object in objectinfo.sort_values(by=['VED']).iterrows():\n",
    "        if type == 'scatter':\n",
    "            xs = np.array(sharpened[object.zstart:object.zend, object.ystart:object.yend, object.xstart:object.xend], copy=True, dtype=np.float32)\n",
    "            sum = np.sum(xs, axis=0)\n",
    "            limit = np.percentile(sum, emptyRatio)\n",
    "            filter = sum >= limit\n",
    "            (endLayer, _, _) = xs.shape\n",
    "            filter = np.repeat([filter], endLayer, 0)\n",
    "            xs[~filter] = np.nan\n",
    "            filtered[object.zstart:object.zend, object.ystart:object.yend, object.xstart:object.xend] = xs\n",
    "        elif type == 'moran':\n",
    "            xs = sharpened[object.zstart:object.zend, object.ystart:object.yend, object.xstart:object.xend]\n",
    "            sum = np.sum(xs, axis=0)\n",
    "            limit = np.percentile(sum, emptyRatio)\n",
    "            filter = sum >= limit\n",
    "            (endLayer, _, _) = xs.shape\n",
    "            filter = np.repeat([filter], endLayer, 0)\n",
    "            avg = np.mean(xs, where=filter)\n",
    "            stddev = np.std(xs, where=filter)\n",
    "            xs = (xs - avg) / avg\n",
    "            xs[~filter] = np.nan\n",
    "            filtered[object.zstart:object.zend, object.ystart:object.yend, object.xstart:object.xend] = xs\n",
    "        elif type == 'spatstat':\n",
    "            # Implement later\n",
    "            print(\"nyi\")\n",
    "    return sharpened\n",
    "\n",
    "def makeNeighbourhood(sharpened, neighbourhood, windowSize):\n",
    "    neighbourkernel = np.array(\n",
    "        [[1, 1, 1],\n",
    "         [1, 1, 1],\n",
    "         [1, 1, 1]]\n",
    "    )/9 if neighbourhood == 'grid' else np.array(\n",
    "        [[1, 2,  1],\n",
    "        [2, 4, 2],\n",
    "        [1, 2,  1]])/16\n",
    "    flatNeighbourhood = np.array([cv2.filter2D(src=layer, ddepth=-1, kernel=neighbourkernel) for layer in sharpened])\n",
    "    (endLayer, _, _) = flatNeighbourhood.shape\n",
    "    neighbourhoodValues = np.array([\n",
    "        np.sum(flatNeighbourhood[layerIndex-windowSize:layerIndex], axis=0)/windowSize\n",
    "        for layerIndex in range(windowSize, endLayer)\n",
    "    ])\n",
    "    return neighbourhoodValues\n",
    "\n",
    "def encode(sharpened, objectinfo, neighbourhoodValues, windowSize, type, buckets, histnormalise):\n",
    "    offset = windowSize // 2\n",
    "\n",
    "    if type == 'spatstat':\n",
    "        print(\"nyi\")\n",
    "    else:\n",
    "        outliervalues = np.full(np.shape(neighbourhoodValues), np.nan)\n",
    "        for index, object in objectinfo.iterrows():\n",
    "            if object.Label == \"KH\":\n",
    "                continue\n",
    "            xs = sharpened[object.zstart+offset:object.zend-windowSize+offset+1, object.ystart:object.yend, object.xstart:object.xend]\n",
    "            ys = neighbourhoodValues[object.zstart:object.zend-windowSize+1, object.ystart:object.yend, object.xstart:object.xend]\n",
    "            filter = np.logical_and(np.isfinite(xs), np.isfinite(ys))\n",
    "            line = np.polyfit(ys[filter].flatten(), xs[filter].flatten(), 1)\n",
    "            p = np.poly1d(line)\n",
    "            outliervalues[object.zstart:object.zend-windowSize+1, object.ystart:object.yend, object.xstart:object.xend] = xs - p(ys)\n",
    "        minval = np.min(outliervalues)\n",
    "        maxval = np.max(outliervalues)\n",
    "        for index, object in objectinfo.iterrows():\n",
    "            if object.Label == \"KH\":\n",
    "                continue\n",
    "            xs = neighbourhoodValues[object.zstart:object.zend, object.ystart:object.yend, object.xstart:object.xend]\n",
    "            filter = np.isfinite(xs)\n",
    "            label = object.Label\n",
    "            hist, _ = np.histogram(xs[filter], bins=buckets, range=(minval, maxval))\n",
    "            if init == False:\n",
    "                X = np.array([hist])\n",
    "                Y = np.array([0 if label == 'GOOD' else 1])\n",
    "                init = True\n",
    "            else:\n",
    "                X = np.append(X, np.array([hist]), 0)\n",
    "                Y = np.append(Y, np.array([0 if label == 'GOOD' else 1]), 0)\n",
    "        \n",
    "        if (histnormalise == 'column'):\n",
    "            X = preprocessing.normalize(X, axis=0)\n",
    "        elif (histnormalise == 'row'):\n",
    "            X = preprocessing.normalize(X, axis=1)\n",
    "    return X, Y\n",
    "\n",
    "def classify(Xtrain, Ytrain, Xtest, Ytest, n_neighbors):\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=\"distance\")\n",
    "    clf.fit(Xtrain, Ytrain)\n",
    "    yfit = clf.predict(Xtest)\n",
    "    return metrics.roc_auc_score(Ytest, yfit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweaking parameter settings\n",
    "types = ['scatter', 'moran']\n",
    "# types = ['scatter', 'moran', 'spatstat']\n",
    "sharpening = ['direct', 'diagonal']\n",
    "neighbourhoodSetting = ['grid', 'euclidean']\n",
    "windowsizes = range(1, 8, 2)\n",
    "buckets = range(30, 151, 30)\n",
    "histnormalise = ('none', 'column', 'row')\n",
    "#bucket-lower-limit?\n",
    "k = range(2, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-12 14:02:14.651415 type:  scatter\n",
      "2022-09-12 14:02:14.651503 sharpSetting:  direct\n",
      "2022-09-12 14:02:14.651519 windowsize:  1\n",
      "2022-09-12 14:02:19.714356 nSetting:  grid\n",
      "2022-09-12 14:02:27.496240 histnorm:  none bucket:  30\n",
      "2022-09-12 14:02:37.787879 histnorm:  none bucket:  60\n",
      "2022-09-12 14:02:47.939511 histnorm:  none bucket:  90\n",
      "2022-09-12 14:02:58.568944 histnorm:  none bucket:  120\n",
      "2022-09-12 14:03:08.376878 histnorm:  none bucket:  150\n",
      "2022-09-12 14:03:18.040410 histnorm:  column bucket:  30\n",
      "2022-09-12 14:03:28.244270 histnorm:  column bucket:  60\n",
      "2022-09-12 14:03:38.448719 histnorm:  column bucket:  90\n",
      "2022-09-12 14:03:48.420133 histnorm:  column bucket:  120\n",
      "2022-09-12 14:03:58.281386 histnorm:  column bucket:  150\n",
      "2022-09-12 14:04:08.245217 histnorm:  row bucket:  30\n",
      "2022-09-12 14:04:17.969932 histnorm:  row bucket:  60\n",
      "2022-09-12 14:04:27.303052 histnorm:  row bucket:  90\n",
      "2022-09-12 14:04:36.629041 histnorm:  row bucket:  120\n",
      "2022-09-12 14:04:46.054785 histnorm:  row bucket:  150\n",
      "2022-09-12 14:04:55.831063 nSetting:  euclidean\n",
      "2022-09-12 14:05:04.127759 histnorm:  none bucket:  30\n",
      "2022-09-12 14:05:12.361276 histnorm:  none bucket:  60\n",
      "2022-09-12 14:05:20.472508 histnorm:  none bucket:  90\n",
      "2022-09-12 14:05:28.493494 histnorm:  none bucket:  120\n",
      "2022-09-12 14:05:36.428384 histnorm:  none bucket:  150\n",
      "2022-09-12 14:05:44.541081 histnorm:  column bucket:  30\n",
      "2022-09-12 14:05:53.185765 histnorm:  column bucket:  60\n",
      "2022-09-12 14:06:01.767998 histnorm:  column bucket:  90\n",
      "2022-09-12 14:06:10.001828 histnorm:  column bucket:  120\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors, metrics\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Preprocessing (sharpening and background filtering)\n",
    "def preprocess(integrals, objectinfo, type, sharpening,  windowSize):\n",
    "    sharpeningKernel = np.array([   [-1, -1,  -1],\n",
    "                                    [-1,  9,  -1],\n",
    "                                    [ -1, -1,  -1]\n",
    "    ]) if sharpening == 'diagonal' else np.array([  [0, -1,  0],\n",
    "                                                    [-1, 5, -1],\n",
    "                                                    [0, -1,  0]])\n",
    "    sharpened = np.array([cv2.filter2D(src=image, ddepth=-1, kernel=sharpeningKernel) for image in integrals])\n",
    "# Sharpening is done\n",
    "    filtered = np.full(np.shape(integrals), np.nan)\n",
    "    for index, object in objectinfo.sort_values(by=['VED']).iterrows():\n",
    "        if type == 'scatter':\n",
    "            xs = np.array(sharpened[object.zstart:object.zend, object.ystart:object.yend, object.xstart:object.xend], copy=True, dtype=np.float32)\n",
    "            sum = np.sum(xs, axis=0)\n",
    "            limit = np.percentile(sum, emptyRatio)\n",
    "            filter = sum >= limit\n",
    "            (endLayer, _, _) = xs.shape\n",
    "            filter = np.repeat([filter], endLayer, 0)\n",
    "            xs[~filter] = np.nan\n",
    "            filtered[object.zstart:object.zend, object.ystart:object.yend, object.xstart:object.xend] = xs\n",
    "        elif type == 'moran':\n",
    "            xs = sharpened[object.zstart:object.zend, object.ystart:object.yend, object.xstart:object.xend]\n",
    "            sum = np.sum(xs, axis=0)\n",
    "            limit = np.percentile(sum, emptyRatio)\n",
    "            filter = sum >= limit\n",
    "            (endLayer, _, _) = xs.shape\n",
    "            filter = np.repeat([filter], endLayer, 0)\n",
    "            avg = np.mean(xs, where=filter)\n",
    "            stddev = np.std(xs, where=filter)\n",
    "            xs = (xs - avg) / avg\n",
    "            xs[~filter] = np.nan\n",
    "            filtered[object.zstart:object.zend, object.ystart:object.yend, object.xstart:object.xend] = xs\n",
    "        elif type == 'spatstat':\n",
    "            # Implement later\n",
    "            print(\"nyi\")\n",
    "    return sharpened\n",
    "\n",
    "def makeNeighbourhood(sharpened, neighbourhood, windowSize):\n",
    "    neighbourkernel = np.array(\n",
    "        [[1, 1, 1],\n",
    "         [1, 1, 1],\n",
    "         [1, 1, 1]]\n",
    "    )/9 if neighbourhood == 'grid' else np.array(\n",
    "        [[1, 2,  1],\n",
    "        [2, 4, 2],\n",
    "        [1, 2,  1]])/16\n",
    "    flatNeighbourhood = np.array([cv2.filter2D(src=layer, ddepth=-1, kernel=neighbourkernel) for layer in sharpened])\n",
    "    (endLayer, _, _) = flatNeighbourhood.shape\n",
    "    neighbourhoodValues = np.array([\n",
    "        np.sum(flatNeighbourhood[layerIndex-windowSize:layerIndex], axis=0)/windowSize\n",
    "        for layerIndex in range(windowSize, endLayer+1)\n",
    "    ])\n",
    "    return neighbourhoodValues\n",
    "\n",
    "def encode(sharpened, objectinfo, neighbourhoodValues, windowSize, type, buckets, histnormalise):\n",
    "    offset = windowSize // 2\n",
    "    init = False\n",
    "\n",
    "    if type == 'spatstat':\n",
    "        print(\"nyi\")\n",
    "    else:\n",
    "        outliervalues = np.full(np.shape(neighbourhoodValues), 0.0)\n",
    "        for index, object in objectinfo.iterrows():\n",
    "            if object.Label == \"KH\":\n",
    "                continue\n",
    "            xs = sharpened[object.zstart+offset:object.zend-windowSize+offset+1, object.ystart:object.yend, object.xstart:object.xend]\n",
    "            ys = neighbourhoodValues[object.zstart:object.zend-windowSize+1, object.ystart:object.yend, object.xstart:object.xend]\n",
    "            filter = np.logical_and(np.isfinite(xs), np.isfinite(ys))\n",
    "            line = np.polyfit(ys[filter].flatten(), xs[filter].flatten(), 1)\n",
    "            p = np.poly1d(line)\n",
    "            outliervalues[object.zstart:object.zend-windowSize+1, object.ystart:object.yend, object.xstart:object.xend] = xs - p(ys)\n",
    "        minval = np.min(outliervalues)\n",
    "        maxval = np.max(outliervalues)\n",
    "        for index, object in objectinfo.iterrows():\n",
    "            if object.Label == \"KH\":\n",
    "                continue\n",
    "            xs = neighbourhoodValues[object.zstart:object.zend, object.ystart:object.yend, object.xstart:object.xend]\n",
    "            filter = np.isfinite(xs)\n",
    "            label = object.Label\n",
    "            hist, _ = np.histogram(xs[filter], bins=buckets, range=(minval, maxval))\n",
    "            if init == False:\n",
    "                X = np.array([hist])\n",
    "                Y = np.array([0 if label == 'GOOD' else 1])\n",
    "                init = True\n",
    "            else:\n",
    "                X = np.append(X, np.array([hist]), 0)\n",
    "                Y = np.append(Y, np.array([0 if label == 'GOOD' else 1]), 0)\n",
    "        \n",
    "        if (histnormalise == 'column'):\n",
    "            X = preprocessing.normalize(X, axis=0)\n",
    "        elif (histnormalise == 'row'):\n",
    "            X = preprocessing.normalize(X, axis=1)\n",
    "    return X, Y\n",
    "\n",
    "def classify(Xtrain, Ytrain, Xtest, Ytest, n_neighbors):\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=\"distance\")\n",
    "    clf.fit(Xtrain, Ytrain)\n",
    "    yfit = clf.predict(Xtest)\n",
    "    return metrics.roc_auc_score(Ytest, yfit), metrics.precision_score(Ytest, yfit), metrics.recall_score(Ytest, yfit)\n",
    "\n",
    "\n",
    "# Now to tie it all together...\n",
    "from datetime import datetime\n",
    "columns = ['type', 'sharpening', 'windowSize', 'neighbourhood', 'buckets', 'histnormalise', 'k-nearest', 'auc', 'precision', 'recall']\n",
    "results = pd.DataFrame(columns=columns)\n",
    "for type in types:\n",
    "    print(datetime.now(), \"type: \", type)\n",
    "    for sharpSetting in sharpening:\n",
    "        print(datetime.now(), \"sharpSetting: \", sharpSetting)\n",
    "        for windowsize in windowsizes:\n",
    "            print(datetime.now(), \"windowsize: \", windowsize)\n",
    "            preprocessed = preprocess(integrals, objectinfo, type, sharpSetting, windowsize)\n",
    "            testpreprocessed = preprocess(testintegrals, testobjectinfo, type, sharpSetting, windowsize)\n",
    "            for nSetting in neighbourhoodSetting:\n",
    "                print(datetime.now(), \"nSetting: \", nSetting)\n",
    "                neighbourhood = makeNeighbourhood(preprocessed, nSetting, windowsize) \n",
    "                testneighbourhood = makeNeighbourhood(testpreprocessed, nSetting, windowsize)\n",
    "                for histnorm in histnormalise:\n",
    "                    for bucket in buckets:\n",
    "                        print(datetime.now(), \"histnorm: \", histnorm, \"bucket: \", bucket)\n",
    "                        Xtrain, Ytrain = encode(preprocessed, objectinfo, neighbourhood, windowsize, type, bucket, histnorm)\n",
    "                        Xtest, Ytest = encode(testpreprocessed, testobjectinfo, testneighbourhood, windowsize, type, bucket, histnorm)\n",
    "                        # Add encode for test as well\n",
    "                        for n_neighbors in k:\n",
    "                            score, precision, recall = classify(Xtrain, Ytrain, Xtest, Ytest, n_neighbors)\n",
    "                            nextRow =  pd.DataFrame([[type, sharpSetting, windowsize, nSetting, bucket, histnorm, n_neighbors, score, precision, recall]], columns=columns)\n",
    "                            results = pd.concat([results, nextRow])\n",
    "                        results.to_csv('out.csv', index=False, header=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('thesis-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b582782fd74adb665333939d2eb8c9995c52902e0db289bedb880e3a83e2d4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
