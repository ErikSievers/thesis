{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from copy import copy\n",
    "from matplotlib import cm, colors\n",
    "import cv2\n",
    "\n",
    "def getTrainObjects(objectsplit=1, upsamplingratio=1, positive_multiplier=1, porositythreshold=0.5, separate_test=True):\n",
    "    emptyRatio = 47\n",
    "    objectwidth = 83\n",
    "    objectheight = 122\n",
    "    xspacing = 133\n",
    "    yspacing = 270\n",
    "    xstart = 293\n",
    "    ystart = 268\n",
    "    xend = 1730\n",
    "    yend = 1770\n",
    "    hsegments = [0,26,50,74,98,122]\n",
    "    powderthickness = 80\n",
    "    endlayer = 187\n",
    "\n",
    "    paths = pathlib.Path('./OT data 80 um/int').glob('*.tif')\n",
    "    paths_sorted = [x for x in paths]\n",
    "    paths_sorted.sort()\n",
    "    block = np.array([np.array(plt.imread(path)) for path in paths_sorted])\n",
    "    integrals = block[0:endlayer]\n",
    "\n",
    "    del paths_sorted\n",
    "    objectinfo = pd.read_csv('Parameters.csv', names=[\"Object\", \"P\", \"S\", \"H\", \"Porosity\", \"Label\"])\n",
    "\n",
    "    objectCoordinates = [[x, x+objectwidth, y, y+objectheight] for y in reversed(range(\n",
    "        ystart, yend, objectheight + yspacing)) for x in range(xstart, xend, xspacing + objectwidth)]\n",
    "    coorddf = pd.DataFrame(objectCoordinates, columns=['xstart', 'xend', 'ystart', 'yend'])\n",
    "    objectinfo = coorddf.join(objectinfo)\n",
    "\n",
    "    objects = np.full((len(objectinfo), endlayer, objectheight, objectwidth), np.nan)\n",
    "\n",
    "    for index, object in objectinfo.iterrows():\n",
    "        objects[index] = integrals[:, object.ystart:object.yend, object.xstart:object.xend]\n",
    "\n",
    "    aggregate = np.sum(objects, axis=(0,1))\n",
    "\n",
    "    emptyRatio = 47\n",
    "    limit = np.percentile(aggregate, emptyRatio)\n",
    "    mask = aggregate >= limit\n",
    "    mask = np.repeat([mask], endlayer, 0)\n",
    "\n",
    "    for object in objects:\n",
    "        object[~mask] = np.nan\n",
    "\n",
    "    # Time to construct the \"real\" dataframe\n",
    "\n",
    "    segmentdf = pd.read_csv('Segments.csv', names=[\"Object\", \"Objectnumber\", \"Segment\", \"P\", \"S\", \"H\", \"Porosity\", \"Area\"])\n",
    "    segmentdf.insert(1, \"VED\", segmentdf.P * 1000/(segmentdf.S * segmentdf.H * powderthickness))\n",
    "    segmentdf.insert(1, \"Label\", np.where(segmentdf.Porosity > porositythreshold, 1, 0))\n",
    "    originalframe = segmentdf.copy()\n",
    "    hs = [[hsegments[j], hsegments[j+1]] for i in range(0, len(objects)) for j in range(0, len(hsegments)-1)]\n",
    "    coorddf = pd.DataFrame(hs, columns=['hstart', 'hend'])\n",
    "    segmentdf = coorddf.join(segmentdf)\n",
    "\n",
    "    # Start of object multiplication \n",
    "    layersPerObject = endlayer // objectsplit\n",
    "    testEnd = endlayer if separate_test else endlayer - layersPerObject * (objectsplit // 3)\n",
    "    zs = [segmentdf.copy().assign(zstart=z, zend=z+layersPerObject) for z in range(0, testEnd-layersPerObject+1, layersPerObject//(upsamplingratio * positive_multiplier))]\n",
    "    testzs = [segmentdf.copy().assign(zstart=testEnd, zend=endlayer)]\n",
    "    trainobjectinfo = pd.concat(zs, ignore_index=True)\n",
    "    trainobjectinfo.drop(trainobjectinfo[(trainobjectinfo.Objectnumber == 28) | (trainobjectinfo.Objectnumber == 21) ].index, inplace=True)\n",
    "    trainobjectinfo.reset_index(drop=True, inplace=True)\n",
    "    testobjectinfo = pd.concat(testzs, ignore_index=True)\n",
    "    testobjectinfo.drop(testobjectinfo[(testobjectinfo.Objectnumber == 28) | (testobjectinfo.Objectnumber == 21) ].index, inplace=True)\n",
    "    testobjectinfo.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Removes extra rows \n",
    "    trainobjectinfo = trainobjectinfo[(trainobjectinfo['Label'] == 1) | (trainobjectinfo['zstart'] % (positive_multiplier) == 0)]\n",
    "\n",
    "    trainobjects = [objects[object.Objectnumber-1, object.zstart:object.zend, object.hstart:object.hend] for index, object in trainobjectinfo.iterrows()]\n",
    "    testobjects = [objects[object.Objectnumber-1, object.zstart:object.zend, object.hstart:object.hend] for index, object in testobjectinfo.iterrows()]\n",
    "\n",
    "    print(\"fetching data with objectsplit: {}, upsamplingratio: {}, positive_multiplier: {}, porositythreshold: {}\".format(objectsplit, upsamplingratio, positive_multiplier, porositythreshold))\n",
    "    return trainobjects, trainobjectinfo, testobjects, testobjectinfo\n",
    "\n",
    "# assert(np.average(np.isfinite(trainobjects)) == 1)\n",
    "# assert(np.average(np.isfinite(testobjects)) == 1)\n",
    "# xs = np.copy(aggregate)\n",
    "# xs[~backgroundmask] = np.nan\n",
    "# plt.imshow(xs)\n",
    "# plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors, metrics\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn import tree\n",
    "import warnings\n",
    "\n",
    "def preprocess(objects, type, sharpening):\n",
    "    rtn = []\n",
    "    # print(rtn.shape)\n",
    "    for index, object in enumerate(objects):\n",
    "        object = np.copy(object)\n",
    "        sharpened = object\n",
    "        if(sharpening != 'none'):\n",
    "            sharpeningKernel = np.array([   [-1, -1,  -1],\n",
    "                                        [-1,  9,  -1],\n",
    "                                        [ -1, -1,  -1]\n",
    "        ]) if sharpening == 'diagonal' else np.array([  [0, -1,  0],\n",
    "                                                        [-1, 5, -1],\n",
    "                                                        [0, -1,  0]])\n",
    "            sharpened = np.array([cv2.filter2D(src=image, ddepth=-1, kernel=sharpeningKernel) for image in object])\n",
    "        # Sharpening is done\n",
    "        if type == 'scatter' or type == 'spatstat':\n",
    "            xs = np.array(sharpened, copy=True, dtype=np.float32)\n",
    "            rtn.append(xs)\n",
    "        elif type == 'moran':\n",
    "            xs = np.array(sharpened, copy=True, dtype=np.float32)\n",
    "            avg = np.nanmean(xs)\n",
    "            stddev = np.nanstd(xs)\n",
    "            xs = (xs - avg) / avg\n",
    "            rtn.append(xs)\n",
    "    return rtn\n",
    "\n",
    "\n",
    "def calculateoutliers(objects, type, neighbourhoodSetting, windowSize):\n",
    "    # c, z, y, x = objects.shape\n",
    "\n",
    "\n",
    "    outlierValues = []\n",
    "    index = 0\n",
    "    # return objects\n",
    "    for object in objects:\n",
    "        object = np.copy(object)\n",
    "        z, y, x = object.shape\n",
    "        # Step 1: calculate neighbourhood\n",
    "        neighbourkernel = np.ones((neighbourhoodSetting, neighbourhoodSetting)) / neighbourhoodSetting**2\n",
    "        flatNeighbourhood = np.array([cv2.filter2D(src=layer, ddepth=-1, kernel=neighbourkernel) for layer in object])\n",
    "        neighbourhoodValues = np.array([\n",
    "            np.sum(flatNeighbourhood[layerIndex-windowSize:layerIndex], axis=0)/windowSize\n",
    "            for layerIndex in range(windowSize, z+1)\n",
    "        ])\n",
    "        # Step 2: calculate outlier\n",
    "        offset = windowSize // 2\n",
    "        endoffset = windowSize - offset - 1\n",
    "\n",
    "        ys = neighbourhoodValues[0:z-windowSize+1]\n",
    "        xs = object[offset:z-endoffset]\n",
    "        filter = np.logical_and(np.isfinite(xs), np.isfinite(ys))\n",
    "\n",
    "        # plt.imshow(xs[0])\n",
    "        # plt.figure()\n",
    "        # plt.imshow(xs[0])\n",
    "        # plt.figure()\n",
    "        # if(index == 58):\n",
    "        #     plt.imshow(xs[0])\n",
    "        #     plt.figure()\n",
    "        #     plt.imshow(ys[0])\n",
    "        #     plt.figure()\n",
    "        #     plt.imshow(filter[0])\n",
    "        #     plt.figure()\n",
    "        #     print(len(np.unique(filter)))\n",
    "        numberOfFilterValues = len(np.unique(filter))\n",
    "        # print(\"filterlength is: \", numberOfFilterValues)\n",
    "        # print(\"index is:\", index)\n",
    "        assert numberOfFilterValues == 2, f\"Expected filter to have two values, got: {numberOfFilterValues}\"\n",
    "        if type == 'spatstat':\n",
    "            outliers = xs - ys\n",
    "            avg = np.mean(outliers[filter])\n",
    "            std = np.std(outliers[filter])\n",
    "            outliers = (outliers - avg) / std\n",
    "            outlierValues.append(outliers)\n",
    "        else:\n",
    "            with warnings.catch_warnings():\n",
    "                line = np.polyfit(xs[filter].flatten(), ys[filter].flatten(), 1)\n",
    "                p = np.poly1d(line)\n",
    "                outlierValues.append(p(xs) - ys)\n",
    "            # plt.scatter(xs[filter].flatten(), ys[filter].flatten())\n",
    "            # plt.axline((-0.1, p(-0.1)), (0, p(0)), linewidth=2, color='b')\n",
    "            # plt.figure()\n",
    "            assert(xs.shape == p(ys).shape)\n",
    "        assert(len(np.unique(outlierValues[index])) > 1)\n",
    "        assert(len(np.unique(np.isfinite(outlierValues[index]))) == 2)\n",
    "        index+=1\n",
    "    # print(\"okidk \", np.average(np.isfinite(outlierValues)))\n",
    "    # assert(np.average(np.isfinite(outlierValues)) > 0.4)\n",
    "    return outlierValues\n",
    "\n",
    "def encode(outlierobjects, buckets, minval=0, maxval=0):\n",
    "    numberOfObjects = len(outlierobjects)\n",
    "    X = np.full((numberOfObjects, buckets), np.nan)\n",
    "    raw = np.concatenate([oo.flatten() for oo in outlierobjects])\n",
    "    filter = np.isfinite(raw)\n",
    "    minval = np.min(raw[filter]) if minval == 0 else minval\n",
    "    maxval = np.max(raw[filter]) if maxval == 0 else maxval\n",
    "    for index in range(0, numberOfObjects):\n",
    "        xs = outlierobjects[index]\n",
    "        filter = np.isfinite(xs)\n",
    "        hist, edges = np.histogram(xs[filter], bins=buckets, range=(minval, maxval), density=True)\n",
    "        X[index] = np.array(hist)\n",
    "    \n",
    "    return X, minval, maxval, edges\n",
    "\n",
    "def classify(Xtrain, Ytrain, Xtest, Ytest, n_neighbors, histnormalise, classifier):\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=\"uniform\") if classifier == 'KNN' else tree.DecisionTreeClassifier()\n",
    "    clf2 = clf\n",
    "    scaler = StandardScaler()\n",
    "    if (histnormalise == True):\n",
    "        clf = Pipeline([('scaler', scaler), ('classifier', clf)])\n",
    "    cvs = cross_val_score(clf, Xtrain, Ytrain, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    clf.fit(Xtrain, Ytrain)\n",
    "    yfit = clf.predict_proba(Xtest)[:,1]\n",
    "    Xtransformed = scaler.transform(Xtest)\n",
    "    for i in range(0,10):\n",
    "        object = Xtrain[i]\n",
    "        bars = len(object)\n",
    "        plt.bar(range(0, bars), height=object, width=1, color='tab:green')\n",
    "        plt.title(\"Original segment \" + str(i%5 + 1) + \" Object \" + str(i // 5 + 1) + \" Label \" + str(Ytrain[i]))\n",
    "        plt.figure()\n",
    "    for i in range(0,10):\n",
    "        object = Xtransformed[i]\n",
    "        bars = len(object)\n",
    "        plt.bar(range(0, bars), height=object, width=1, color='tab:green')\n",
    "        plt.title(\"Transformed segment \" + str(i%5 + 1) + \" Object \" + str(i // 5 + 1) + \" Label \" + str(Ytrain[i]))\n",
    "        plt.figure()\n",
    "    return cvs.mean(), metrics.roc_auc_score(Ytest, yfit), clf2.kneighbors(Xtransformed, return_distance=False) if classifier == 'KNN' else np.array([])\n",
    "\n",
    "    clf = neighbors.KNeighborsClassifier() if type == 'KNN' else tree.DecisionTreeClassifier()\n",
    "    clf2 = clf\n",
    "    scaler = StandardScaler()\n",
    "    if (histnormalise == True):\n",
    "        clf = Pipeline([('scaler', scaler), ('classifier', clf)])\n",
    "    # cvs = cross_val_score(clf, Xtrain, Ytrain, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    clf.fit(Xtrain, Ytrain)\n",
    "    Yfit = clf.predict(Xtest)\n",
    "    Yprobs = clf.predict_proba(Xtest)\n",
    "    Xtransformed = scaler.transform(Xtest)\n",
    "\n",
    "    return Yfit, Yprobs, clf2.kneighbors(Xtransformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainobjects, trainobjectinfo, testobjects, testobjectinfo = getTrainObjects(porositythreshold=0.25, objectsplit=3, separate_test=False)\n",
    "\n",
    "# Show original\n",
    "plt.imshow(trainobjects[1, 93], vmin=0)\n",
    "plt.axis('off')\n",
    "plt.savefig('figures/originaltree.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.title(\"Original\")\n",
    "plt.figure()\n",
    "\n",
    "tmpobject = np.copy(trainobjects[1])\n",
    "tmpobject[~trainmask] = np.nan\n",
    "plt.imshow(tmpobject[93], vmin=0)\n",
    "plt.axis('off')\n",
    "plt.savefig('figures/nobackground.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.colorbar()\n",
    "plt.savefig('figures/nobackgroundcolorbar.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.title(\"Background gone\")\n",
    "plt.figure()\n",
    "\n",
    "# Show outlier\n",
    "rtn = np.full(trainobjects.shape, np.nan)\n",
    "rtnscatter = np.full(trainobjects.shape, np.nan)\n",
    "    # print(rtn.shape)\n",
    "for index, object in enumerate(trainobjects):\n",
    "    xs = np.array(object, copy=True, dtype=np.float32)\n",
    "    xsscatter = np.array(object, copy=True, dtype=np.float32)\n",
    "    xsscatter[~trainmask] = np.nan\n",
    "    rtnscatter[index] = xsscatter\n",
    "    avg = np.mean(xs, where=trainmask)\n",
    "    stddev = np.std(xs, where=trainmask)\n",
    "    xs = (xs - avg) / avg\n",
    "    xs[~trainmask] = np.nan\n",
    "    rtn[index] = xs\n",
    "\n",
    "windowSize = 3\n",
    "objects = rtn\n",
    "\n",
    "plt.imshow(objects[1, 93])\n",
    "plt.title(\"Normalised (for moran)\")\n",
    "plt.figure()\n",
    "\n",
    "c, z, y, x = objects.shape\n",
    "outlierValues = np.full((c, z + 1 - windowSize, y, x), np.nan)\n",
    "for index, object in enumerate(objects):\n",
    "    # Step 1: calculate neighbourhood\n",
    "    neighbourkernel = np.ones((3, 3)) / 9\n",
    "    flatNeighbourhood = np.array([cv2.filter2D(src=layer, ddepth=-1, kernel=neighbourkernel) for layer in object])\n",
    "    neighbourhoodValues = np.array([\n",
    "        np.sum(flatNeighbourhood[layerIndex-windowSize:layerIndex], axis=0)/windowSize\n",
    "        for layerIndex in range(windowSize, z+1)\n",
    "    ])\n",
    "    # Step 2: calculate outlier\n",
    "    offset = windowSize // 2\n",
    "    endoffset = windowSize - offset - 1\n",
    "\n",
    "    xs = object[offset:z-endoffset]\n",
    "    ys = neighbourhoodValues[0:z-windowSize+1]\n",
    "    filter = np.logical_and(np.isfinite(xs), np.isfinite(ys))\n",
    "\n",
    "    assert(len(set(filter.flatten())) == 2)    \n",
    "    line = np.polyfit(ys[filter].flatten(), xs[filter].flatten(), 1)\n",
    "    p = np.poly1d(line)\n",
    "    outlierValues[index] = xs - p(ys)\n",
    "    assert(outlierValues[index].shape == xs.shape == p(ys).shape)\n",
    "    assert(len(np.unique(outlierValues[index])) > 1)\n",
    "    assert(len(np.unique(np.isfinite(outlierValues[index]))) == 2)\n",
    "\n",
    "    if(index == 1):\n",
    "        plt.scatter(ys[92].flatten(), xs[92].flatten(), c=(xs - p(ys))[92].flatten(), s=10)\n",
    "        # plt.scatter(ys2[filter2].flatten(), xs2[filter2].flatten(), color='tab:red', s=10, alpha=0.125)\n",
    "        plt.axline((-0.1, p(-0.1)), (0, p(0)), linewidth=2, color='tab:blue')\n",
    "        plt.xlabel(\"Neighbourhood value\")\n",
    "        plt.ylabel(\"Local value\")\n",
    "        plt.savefig('figures/moran-color-example.pdf', dpi=300, bbox_inches='tight')\n",
    "        plt.title(\"Moran scatter plot for points in a high porosity object\")\n",
    "        plt.figure()\n",
    "\n",
    "assert(np.average(np.isfinite(outlierValues)) > 0.4)\n",
    "plt.imshow(outlierValues[1, 92])\n",
    "plt.axis('off')\n",
    "plt.savefig('figures/moranoutliervalues.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.colorbar()\n",
    "plt.savefig('figures/moranoutliercolorbar.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.title(\"Moran outlier values\")\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "\n",
    "objects = rtnscatter\n",
    "\n",
    "c, z, y, x = objects.shape\n",
    "outlierValuesScatter = np.full((c, z + 1 - windowSize, y, x), np.nan)\n",
    "outlierValuesSpatstat = np.full((c, z + 1 - windowSize, y, x), np.nan)\n",
    "nhood = np.full((c, z + 1 - windowSize, y, x), np.nan)\n",
    "for index, object in enumerate(objects):\n",
    "    # Step 1: calculate neighbourhood\n",
    "    neighbourkernel = np.ones((3, 3)) / 3**2\n",
    "    flatNeighbourhood = np.array([cv2.filter2D(src=layer, ddepth=-1, kernel=neighbourkernel) for layer in object])\n",
    "    # funny = np.logical_and(np.isfinite(object), ~np.isfinite(flatNeighbourhood))\n",
    "    # flatNeighbourhood[funny] = np.nanmean(flatNeighbourhood)\n",
    "    neighbourhoodValues = np.array([\n",
    "        np.sum(flatNeighbourhood[layerIndex-windowSize:layerIndex], axis=0)/windowSize\n",
    "        for layerIndex in range(windowSize, z+1)\n",
    "    ])\n",
    "    # Step 2: calculate outlier\n",
    "    offset = windowSize // 2\n",
    "    endoffset = windowSize - offset - 1\n",
    "\n",
    "    xs = object[offset:z-endoffset]\n",
    "    ys = neighbourhoodValues[0:z-windowSize+1]\n",
    "    filter = np.logical_and(np.isfinite(xs), np.isfinite(ys))\n",
    "    funny = np.logical_and(np.isfinite(xs), ~np.isfinite(ys))\n",
    "\n",
    "\n",
    "    assert(len(set(filter.flatten())) == 2)    \n",
    "    line = np.polyfit(ys[filter].flatten(), xs[filter].flatten(), 1)\n",
    "    p = np.poly1d(line)\n",
    "    outlierValuesScatter[index] = xs - p(ys)\n",
    "    assert(outlierValuesScatter[index].shape == xs.shape == p(ys).shape)\n",
    "    assert(len(np.unique(outlierValues[index])) > 1)\n",
    "    assert(len(np.unique(np.isfinite(outlierValues[index]))) == 2)\n",
    "    outliers = xs - ys\n",
    "    avg = np.nanmean(outliers)\n",
    "    std = np.nanstd(outliers)\n",
    "    outliers = (outliers - avg) / std\n",
    "    outlierValuesSpatstat[index] = outliers\n",
    "    nhood[index] = neighbourhoodValues\n",
    "    if(index == 1):\n",
    "        plt.scatter(ys[92].flatten(), xs[92].flatten(), c=(xs - p(ys))[92].flatten(), s=10)\n",
    "        # plt.scatter(ys2[filter2].flatten(), xs2[filter2].flatten(), color='tab:red', s=10, alpha=0.125)\n",
    "        plt.axline((10000, p(10000)), (10001, p(10001)), linewidth=2, color='tab:blue')\n",
    "        plt.xlabel(\"Neighbourhood value\")\n",
    "        plt.ylabel(\"Local value\")\n",
    "        plt.savefig('figures/scatter-color-example.pdf', dpi=300, bbox_inches='tight')\n",
    "        plt.title(\"Scatter plot for points in a high porosity object\")\n",
    "        plt.figure()\n",
    "\n",
    "assert(np.average(np.isfinite(outlierValues)) > 0.4)\n",
    "plt.imshow(outlierValuesScatter[1, 92])\n",
    "plt.axis('off')\n",
    "plt.savefig('figures/scatteroutlier.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.colorbar()\n",
    "plt.savefig('figures/scatteroutliercolorbar.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.title(\"Scatter outlier values\")\n",
    "plt.figure()\n",
    "\n",
    "plt.imshow(outlierValuesSpatstat[1, 92])\n",
    "plt.axis('off')\n",
    "plt.savefig('figures/spatstatoutlier.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.colorbar()\n",
    "plt.savefig('figures/spatstatoutliercolorbar.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.title(\"Spatstat outlier values\")\n",
    "plt.figure()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('thesis-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b582782fd74adb665333939d2eb8c9995c52902e0db289bedb880e3a83e2d4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
