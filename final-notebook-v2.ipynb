{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as final-notebook except this one doesn't keep all objects in the same matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from copy import copy\n",
    "from matplotlib import cm, colors\n",
    "import cv2\n",
    "\n",
    "emptyRatio = 47\n",
    "objectwidth = 83\n",
    "objectheight = 122\n",
    "xspacing = 133\n",
    "yspacing = 270\n",
    "xstart = 293\n",
    "ystart = 268\n",
    "xend = 1730\n",
    "yend = 1770\n",
    "powderthickness = 80\n",
    "endlayer = 187\n",
    "\n",
    "paths = pathlib.Path('./OT data 80 um/int').glob('*.tif')\n",
    "paths_sorted = [x for x in paths]\n",
    "paths_sorted.sort()\n",
    "block = np.array([np.array(plt.imread(path)) for path in paths_sorted])\n",
    "integrals = block[0:endlayer]\n",
    "\n",
    "del paths_sorted\n",
    "objectinfo = pd.read_csv('Parameters.csv', names=[\"Object\", \"P\", \"S\", \"H\", \"Porosity\", \"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectsplit = 3\n",
    "upsamplingratio = 4\n",
    "positive_multiplier = 2\n",
    "layersPerObject = endlayer // objectsplit\n",
    "# Approximate one third test data\n",
    "testEnd = endlayer - layersPerObject * (objectsplit // 3)\n",
    "\n",
    "objectinfo.insert(1, \"VED\", objectinfo.P * 1000/(objectinfo.S * objectinfo.H * powderthickness))\n",
    "objectCoordinates = [[x, x+objectwidth, y, y+objectheight] for y in reversed(range(\n",
    "    ystart, yend, objectheight + yspacing)) for x in range(xstart, xend, xspacing + objectwidth)]\n",
    "coorddf = pd.DataFrame(objectCoordinates, columns=['xstart', 'xend', 'ystart', 'yend'])\n",
    "objectinfo = coorddf.join(objectinfo)\n",
    "objectinfo.drop(objectinfo[objectinfo.Label == 'KH'].index, inplace=True)\n",
    "objectinfo.replace('GOOD', 0, inplace=True)\n",
    "objectinfo.replace('LOF', 1, inplace=True)\n",
    "\n",
    "# positive_multiplier = int(1 // np.average(np.array(objectinfo.loc[:,\"Label\"])))\n",
    "\n",
    "### Old version before upsampling\n",
    "# zs = [objectinfo.copy().assign(zstart=z, zend=z+layersPerObject) for z in range(0, testEnd-layersPerObject, layersPerObject)]\n",
    "# testzs = [objectinfo.copy().assign(zstart=z, zend=z+layersPerObject) for z in range(testEnd, endlayer-layersPerObject+1, layersPerObject)]\n",
    "### End of old version\n",
    "\n",
    "zs = [objectinfo.copy().assign(zstart=z, zend=z+layersPerObject) for z in range(0, testEnd-layersPerObject, layersPerObject//(upsamplingratio * positive_multiplier))]\n",
    "testzs = [objectinfo.copy().assign(zstart=testEnd, zend=endlayer)]\n",
    "\n",
    "trainobjectinfo = pd.concat(zs, ignore_index=True)\n",
    "# This line removes all the lines from the dataframe that aren't created because of the positive_multiplier\n",
    "trainobjectinfo = trainobjectinfo[(trainobjectinfo['Label'] == 1) | (trainobjectinfo['zstart'] % (positive_multiplier) == 0)]\n",
    "\n",
    "testobjectinfo = pd.concat(testzs, ignore_index=True)\n",
    "\n",
    "trainobjectinfo.reset_index(drop=True, inplace=True)\n",
    "testobjectinfo.reset_index(drop=True, inplace=True)\n",
    "\n",
    "del zs\n",
    "del testzs\n",
    "del coorddf\n",
    "del objectCoordinates\n",
    "del objectinfo\n",
    "\n",
    "trainobjects = np.full((len(trainobjectinfo), layersPerObject, objectheight, objectwidth), np.nan)\n",
    "testobjects = np.full((len(testobjectinfo), endlayer-testEnd, objectheight, objectwidth), np.nan)\n",
    "\n",
    "\n",
    "for index, object in trainobjectinfo.iterrows():\n",
    "    trainobjects[index-1] = integrals[object.zstart:object.zend, object.ystart:object.yend, object.xstart:object.xend]\n",
    "for index, object in testobjectinfo.iterrows():\n",
    "    testobjects[index-1] = integrals[object.zstart:object.zend, object.ystart:object.yend, object.xstart:object.xend]\n",
    "\n",
    "aggregate = np.sum(trainobjects, axis=(0,1))\n",
    "\n",
    "emptyRatio = 47\n",
    "limit = np.percentile(aggregate, emptyRatio)\n",
    "backgroundmask = aggregate >= limit\n",
    "trainmask = np.repeat([backgroundmask], layersPerObject, 0)\n",
    "# xs = np.copy(aggregate)\n",
    "# xs[~backgroundmask] = np.nan\n",
    "# plt.imshow(xs)\n",
    "# plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors, metrics\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime\n",
    "\n",
    "def preprocess(objects, type, sharpening, backgroundmask):\n",
    "    rtn = np.full(objects.shape, np.nan)\n",
    "    # print(rtn.shape)\n",
    "    for index, object in enumerate(objects):\n",
    "        sharpeningKernel = np.array([   [-1, -1,  -1],\n",
    "                                        [-1,  9,  -1],\n",
    "                                        [ -1, -1,  -1]\n",
    "        ]) if sharpening == 'diagonal' else np.array([  [0, -1,  0],\n",
    "                                                        [-1, 5, -1],\n",
    "                                                        [0, -1,  0]])\n",
    "        sharpened = np.array([cv2.filter2D(src=image, ddepth=-1, kernel=sharpeningKernel) for image in object])\n",
    "        # if(sharpening == 'none'):\n",
    "        #     sharpened = object\n",
    "    # Sharpening is done\n",
    "        if type == 'scatter' or type == 'spatstat':\n",
    "            xs = np.array(sharpened, copy=True, dtype=np.float32)\n",
    "            (endLayer, _, _) = xs.shape\n",
    "            xs[~backgroundmask] = np.nan\n",
    "            rtn[index] = xs\n",
    "        elif type == 'moran':\n",
    "            xs = np.array(sharpened, copy=True, dtype=np.float32)\n",
    "            (endLayer, _, _) = xs.shape\n",
    "            avg = np.mean(xs, where=backgroundmask)\n",
    "            stddev = np.std(xs, where=backgroundmask)\n",
    "            xs = (xs - avg) / avg\n",
    "            xs[~backgroundmask] = np.nan\n",
    "            rtn[index] = xs\n",
    "    return rtn\n",
    "\n",
    "\n",
    "def calculateoutliers(objects, type, neighbourhoodSetting, windowSize):\n",
    "    c, z, y, x = objects.shape\n",
    "\n",
    "    outlierValues = np.full((c, z + 1 - windowSize, y, x), np.nan)\n",
    "    for index, object in enumerate(objects):\n",
    "        # Step 1: calculate neighbourhood\n",
    "        neighbourkernel = np.array(\n",
    "            [[1, 1, 1],\n",
    "            [1, 1, 1],\n",
    "            [1, 1, 1]]\n",
    "        )/9 if neighbourhoodSetting == 'grid' else np.array(\n",
    "            [[1, 2,  1],\n",
    "            [2, 4, 2],\n",
    "            [1, 2,  1]])/16\n",
    "        flatNeighbourhood = np.array([cv2.filter2D(src=layer, ddepth=-1, kernel=neighbourkernel) for layer in object])\n",
    "        neighbourhoodValues = np.array([\n",
    "            np.sum(flatNeighbourhood[layerIndex-windowSize:layerIndex], axis=0)/windowSize\n",
    "            for layerIndex in range(windowSize, z+1)\n",
    "        ])\n",
    "        # Step 2: calculate outlier\n",
    "        offset = windowSize // 2\n",
    "        endoffset = windowSize - offset - 1\n",
    "\n",
    "        xs = object[offset:z-endoffset]\n",
    "        ys = neighbourhoodValues[0:z-windowSize+1]\n",
    "        filter = np.logical_and(np.isfinite(xs), np.isfinite(ys))\n",
    "\n",
    "        assert(len(set(filter.flatten())) == 2)\n",
    "        if type == 'spatstat':\n",
    "            outliers = xs - ys\n",
    "            avg = np.mean(outliers[filter])\n",
    "            std = np.std(outliers[filter])\n",
    "            outliers = (outliers - avg) / std\n",
    "            outlierValues[index] = outliers\n",
    "        else:\n",
    "            # Is the axis right for moran/scatter?\n",
    "            # print(offset, endoffset, object.shape)\n",
    "            line = np.polyfit(ys[filter].flatten(), xs[filter].flatten(), 1)\n",
    "            p = np.poly1d(line)\n",
    "            outlierValues[index] = xs - p(ys)\n",
    "            assert(outlierValues[index].shape == xs.shape == p(ys).shape)\n",
    "        assert(len(np.unique(outlierValues[index])) > 1)\n",
    "        assert(len(np.unique(np.isfinite(outlierValues[index]))) == 2)\n",
    "    assert(np.average(np.isfinite(outlierValues)) > 0.4)\n",
    "    return outlierValues\n",
    "\n",
    "def encode(outlierobjects, type, buckets, histnormalise, minval=0, maxval=0):\n",
    "    numberOfObjects, _, _, _ = outlierobjects.shape\n",
    "    X = np.full((numberOfObjects, buckets), np.nan)\n",
    "    filter = np.isfinite(outlierobjects)\n",
    "    minval = np.min(outlierobjects[filter]) if minval == 0 else minval\n",
    "    maxval = np.max(outlierobjects[filter]) if maxval == 0 else maxval\n",
    "    for index in range(0, numberOfObjects):\n",
    "        xs = outlierobjects[index]\n",
    "        filter = np.isfinite(xs)\n",
    "        hist, edges = np.histogram(xs[filter], bins=buckets, range=(minval, maxval), density=True)\n",
    "        X[index] = np.array(hist)\n",
    "    \n",
    "    if (histnormalise == 'column'):\n",
    "        X = preprocessing.normalize(X, axis=0)\n",
    "    elif (histnormalise == 'row'):\n",
    "        X = preprocessing.normalize(X, axis=1)\n",
    "    return X, minval, maxval, edges\n",
    "\n",
    "def classify(Xtrain, Ytrain, Xtest, Ytest, n_neighbors):\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=\"distance\")\n",
    "    cvscore = cross_val_score(clf, Xtrain, Ytrain, cv=5, scoring='roc_auc', n_jobs=-1).mean()\n",
    "    clf.fit(Xtrain, Ytrain)\n",
    "    yfit = clf.predict(Xtest)\n",
    "    return cvscore, metrics.roc_auc_score(Ytest, yfit), metrics.precision_score(Ytest, yfit, zero_division=0), metrics.recall_score(Ytest, yfit, zero_division=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter settings\n",
    "types = ['scatter', 'spatstat', 'moran', ]\n",
    "sharpening = ['none', 'direct', 'diagonal']\n",
    "windowsizes = [1, 3, 5, 7]\n",
    "neighbourhoodSetting = ['grid', 'euclidean']\n",
    "bins = [30, 60, 90, 120, 150]\n",
    "histnormalise = ['none', 'row']\n",
    "k = [2,3,4,5,10,15,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:43:20 Processing type:  scatter  sharpening:  none\n",
      "16:43:21 Processing windowSize:  1  neighbourhood:  grid\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/erik/Git/thesis/final-notebook-v2.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/erik/Git/thesis/final-notebook-v2.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m Xtest, _, _, _ \u001b[39m=\u001b[39m encode(testoutliers, \u001b[39mtype\u001b[39m, bucket, histnorm, minval\u001b[39m=\u001b[39mminval, maxval\u001b[39m=\u001b[39mmaxval)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/erik/Git/thesis/final-notebook-v2.ipynb#W5sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mfor\u001b[39;00m n_neighbors \u001b[39min\u001b[39;00m k:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/erik/Git/thesis/final-notebook-v2.ipynb#W5sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     cvscore, score, precision, recall \u001b[39m=\u001b[39m classify(Xtrain, Ytrain, Xtest, Ytest, n_neighbors)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/erik/Git/thesis/final-notebook-v2.ipynb#W5sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     nextRow \u001b[39m=\u001b[39m  pd\u001b[39m.\u001b[39mDataFrame([[\u001b[39mtype\u001b[39m, sharpSetting, windowsize, nSetting, bucket, histnorm, n_neighbors, cvscore, score, precision, recall]], columns\u001b[39m=\u001b[39mcolumns)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/erik/Git/thesis/final-notebook-v2.ipynb#W5sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     results \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([results, nextRow])\n",
      "\u001b[1;32m/Users/erik/Git/thesis/final-notebook-v2.ipynb Cell 6\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(Xtrain, Ytrain, Xtest, Ytest, n_neighbors)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/erik/Git/thesis/final-notebook-v2.ipynb#W5sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclassify\u001b[39m(Xtrain, Ytrain, Xtest, Ytest, n_neighbors):\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/erik/Git/thesis/final-notebook-v2.ipynb#W5sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m     clf \u001b[39m=\u001b[39m neighbors\u001b[39m.\u001b[39mKNeighborsClassifier(n_neighbors, weights\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdistance\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/erik/Git/thesis/final-notebook-v2.ipynb#W5sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m     cvscore \u001b[39m=\u001b[39m cross_val_score(clf, Xtrain, Ytrain, cv\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mroc_auc\u001b[39;49m\u001b[39m'\u001b[39;49m, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mmean()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/erik/Git/thesis/final-notebook-v2.ipynb#W5sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m     clf\u001b[39m.\u001b[39mfit(Xtrain, Ytrain)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/erik/Git/thesis/final-notebook-v2.ipynb#W5sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m     yfit \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(Xtest)\n",
      "File \u001b[0;32m~/Git/thesis/thesis-env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    527\u001b[0m )\n\u001b[1;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Git/thesis/thesis-env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m    269\u001b[0m         X,\n\u001b[1;32m    270\u001b[0m         y,\n\u001b[1;32m    271\u001b[0m         scorers,\n\u001b[1;32m    272\u001b[0m         train,\n\u001b[1;32m    273\u001b[0m         test,\n\u001b[1;32m    274\u001b[0m         verbose,\n\u001b[1;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    276\u001b[0m         fit_params,\n\u001b[1;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/Git/thesis/thesis-env/lib/python3.9/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1057\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/Git/thesis/thesis-env/lib/python3.9/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    936\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/Git/thesis/thesis-env/lib/python3.9/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.14/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.14/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now to tie it all together...\n",
    "columns = ['type', 'sharpening', 'windowSize', 'neighbourhood', 'buckets', 'histnormalise', 'k-nearest', 'cv-auc', 'test-auc', 'test-precision', 'test-recall']\n",
    "results = pd.DataFrame(columns=columns)\n",
    "Ytrain = np.array(trainobjectinfo.loc[:,\"Label\"])\n",
    "Ytest = np.array(testobjectinfo.loc[:,\"Label\"])\n",
    "for type in types:\n",
    "    for sharpSetting in sharpening:\n",
    "        print(datetime.now().strftime(\"%H:%M:%S\"), \"Processing type: \", type, \" sharpening: \", sharpSetting)\n",
    "        # trainpreprocessed = np.apply_along_axis(preprocess, 1, trainobjects, type, sharpSetting)\n",
    "        trainpreprocessed =preprocess(trainobjects, type, sharpSetting, trainmask)\n",
    "        testpreprocessed =preprocess(testobjects, type, sharpSetting, trainmask)\n",
    "        for windowsize in windowsizes:\n",
    "            for nSetting in neighbourhoodSetting:\n",
    "                print(datetime.now().strftime(\"%H:%M:%S\"), \"Processing windowSize: \", windowsize, \" neighbourhood: \", nSetting)\n",
    "                trainoutliers = calculateoutliers(trainpreprocessed, type, nSetting, windowsize)\n",
    "                testoutliers = calculateoutliers(testpreprocessed, type, nSetting, windowsize)\n",
    "                \n",
    "                for histnorm in histnormalise:\n",
    "                    for bucket in bins:\n",
    "                        Xtrain, minval, maxval, edges = encode(trainoutliers, type, bucket, histnorm)\n",
    "                        Xtest, _, _, _ = encode(testoutliers, type, bucket, histnorm, minval=minval, maxval=maxval)\n",
    "                        for n_neighbors in k:\n",
    "                            cvscore, score, precision, recall = classify(Xtrain, Ytrain, Xtest, Ytest, n_neighbors)\n",
    "                            nextRow =  pd.DataFrame([[type, sharpSetting, windowsize, nSetting, bucket, histnorm, n_neighbors, cvscore, score, precision, recall]], columns=columns)\n",
    "                            results = pd.concat([results, nextRow])\n",
    "                        results.to_csv('out13.csv', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug cell\n",
    "\n",
    "type = \"moran\"\n",
    "sharpSetting = \"diagonal\"\n",
    "windowSize = 5\n",
    "histnorm = \"none\"\n",
    "bucket = 30\n",
    "nSetting = \"euclidean\"\n",
    "\n",
    "columns = ['type', 'sharpening', 'windowSize', 'neighbourhood', 'buckets', 'histnormalise', 'k-nearest', 'auc', 'precision', 'recall']\n",
    "results = pd.DataFrame(columns=columns)\n",
    "Ytrain = np.array(trainobjectinfo.loc[:,\"Label\"])\n",
    "Ytest = np.array(testobjectinfo.loc[:,\"Label\"])\n",
    "\n",
    "# Att validera:\n",
    "# Träningsset har flera klasser\n",
    "# Testset har flera klasses\n",
    "# Bilder i varje steg\n",
    "assert(set(Ytest) == set(Ytrain))\n",
    "# trainpreprocessed = np.apply_along_axis(preprocess, 1, trainobjects, type, sharpSetting)\n",
    "trainpreprocessed = preprocess(trainobjects, type, sharpSetting)\n",
    "testpreprocessed = preprocess(testobjects, type, sharpSetting)\n",
    "\n",
    "plt.title(\"training 22 start\")\n",
    "plt.imshow(trainobjects[2][2])\n",
    "plt.figure()\n",
    "plt.title(\"test 22 start\")\n",
    "plt.imshow(testobjects[2][2])\n",
    "plt.figure()\n",
    "plt.title(\"training 22 preprocessed\")\n",
    "plt.imshow(trainpreprocessed[2][2])\n",
    "plt.figure()\n",
    "plt.title(\"test 22 preprocessed\")\n",
    "plt.imshow(testpreprocessed[2][2])\n",
    "plt.figure()\n",
    "# trainoutliers = np.apply_along_axis(calculateoutliers, 1, trainpreprocessed, type, nSetting, windowsize)\n",
    "trainoutliers = calculateoutliers(trainpreprocessed, type, nSetting, windowsize)\n",
    "testoutliers = calculateoutliers(testpreprocessed, type, nSetting, windowsize)\n",
    "print(\"train 2 outliers: \", np.unique(trainoutliers[2]))\n",
    "print(\"test 2 outliers: \", np.unique(testoutliers[2]))\n",
    "print(\"train 1 outliers: \", np.unique(trainoutliers[1]))\n",
    "print(\"test 1 outliers: \", np.unique(testoutliers[1]))\n",
    "plt.title(\"train 22 outliers\")\n",
    "plt.imshow(trainoutliers[2][2])\n",
    "plt.figure()\n",
    "plt.title(\"test 22 outliers\")\n",
    "plt.imshow(testoutliers[2][2])\n",
    "plt.figure()\n",
    "Xtrain, minval, maxval = encode(trainoutliers, type, bucket, histnorm)\n",
    "Xtest, _, _ = encode(testoutliers, type, bucket, histnorm, minval=minval, maxval=maxval)\n",
    "print(\"train 2 outliers: \", np.unique(trainoutliers[2]))\n",
    "print(\"test 2 outliers: \", np.unique(testoutliers[2]))\n",
    "print(\"train 1 outliers: \", np.unique(trainoutliers[1]))\n",
    "print(\"test 1 outliers: \", np.unique(testoutliers[1]))\n",
    "plt.title(\"train 2 outliers\")\n",
    "plt.hist(trainoutliers[2].flatten(), bins=bucket, range=(minval, maxval))\n",
    "plt.yscale('log')\n",
    "plt.figure()\n",
    "plt.title(\"test 2 outliers\")\n",
    "plt.hist(testoutliers[2].flatten(), bins=bucket, range=(minval, maxval))\n",
    "plt.yscale('log')\n",
    "plt.figure()\n",
    "plt.title(\"All outliers\")\n",
    "plt.hist(testoutliers.flatten(), bins=bucket, range=(minval, maxval))\n",
    "plt.yscale('log')\n",
    "plt.figure()\n",
    "# Add encode for test as well\n",
    "for n_neighbors in k:\n",
    "    score, precision, recall = classify(Xtrain, Ytrain, Xtest, Ytest, n_neighbors)\n",
    "    nextRow =  pd.DataFrame([[type, sharpSetting, windowsize, nSetting, bucket, histnorm, n_neighbors, score, precision, recall]], columns=columns)\n",
    "    results = pd.concat([results, nextRow])\n",
    "results.to_csv('out2.csv', index=False, header=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('thesis-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b582782fd74adb665333939d2eb8c9995c52902e0db289bedb880e3a83e2d4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
