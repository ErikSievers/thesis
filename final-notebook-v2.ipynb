{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as final-notebook except this one doesn't keep all objects in the same matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from copy import copy\n",
    "from matplotlib import cm, colors\n",
    "import cv2\n",
    "\n",
    "emptyRatio = 47\n",
    "objectwidth = 83\n",
    "objectheight = 122\n",
    "xspacing = 133\n",
    "yspacing = 270\n",
    "xstart = 293\n",
    "ystart = 268\n",
    "xend = 1730\n",
    "yend = 1770\n",
    "powderthickness = 80\n",
    "endlayer = 187\n",
    "objectsplit = 13\n",
    "\n",
    "layersPerObject = endlayer // objectsplit\n",
    "# Approximate one third test data\n",
    "testEnd = endlayer - layersPerObject * (objectsplit // 3)\n",
    "\n",
    "paths = pathlib.Path('./OT data 80 um/int').glob('*.tif')\n",
    "paths_sorted = [x for x in paths]\n",
    "paths_sorted.sort()\n",
    "block = np.array([np.array(plt.imread(path)) for path in paths_sorted])\n",
    "integrals = block[0:endlayer]\n",
    "\n",
    "del paths_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsamplingratio = 1\n",
    "\n",
    "objectinfo = pd.read_csv('Parameters.csv', names=[\"Object\", \"P\", \"S\", \"H\", \"Porosity\", \"Label\"])\n",
    "objectinfo.insert(1, \"VED\", objectinfo.P * 1000/(objectinfo.S * objectinfo.H * powderthickness))\n",
    "objectCoordinates = [[x, x+objectwidth, y, y+objectheight] for y in reversed(range(\n",
    "    ystart, yend, objectheight + yspacing)) for x in range(xstart, xend, xspacing + objectwidth)]\n",
    "coorddf = pd.DataFrame(objectCoordinates, columns=['xstart', 'xend', 'ystart', 'yend'])\n",
    "objectinfo = coorddf.join(objectinfo)\n",
    "objectinfo.drop(objectinfo[objectinfo.Label == 'KH'].index, inplace=True)\n",
    "objectinfo.replace('GOOD', 0, inplace=True)\n",
    "objectinfo.replace('LOF', 1, inplace=True)\n",
    "\n",
    "positive_multiplier = int(1 // np.average(np.array(objectinfo.loc[:,\"Label\"])))\n",
    "\n",
    "### Old version before upsampling\n",
    "# zs = [objectinfo.copy().assign(zstart=z, zend=z+layersPerObject) for z in range(0, testEnd-layersPerObject, layersPerObject)]\n",
    "# testzs = [objectinfo.copy().assign(zstart=z, zend=z+layersPerObject) for z in range(testEnd, endlayer-layersPerObject+1, layersPerObject)]\n",
    "### End of old version\n",
    "\n",
    "zs = [objectinfo.copy().assign(zstart=z, zend=z+layersPerObject) for z in range(0, testEnd-layersPerObject, layersPerObject//(upsamplingratio * positive_multiplier))]\n",
    "testzs = [objectinfo.copy().assign(zstart=testEnd, zend=endlayer)]\n",
    "trainobjectinfo = pd.concat(zs, ignore_index=True)\n",
    "dataframe = trainobjectinfo.copy()\n",
    "# This line removes all the lines from the dataframe that aren't created because of the positive_multiplier\n",
    "trainobjectinfo = trainobjectinfo[(trainobjectinfo['Label'] == 1) | (trainobjectinfo['zstart'] % (positive_multiplier) == 0)]\n",
    "\n",
    "# Vill ta bort (positibe - 1) / positive. Så alla som inte är jämnt delbara med positive?\n",
    "testobjectinfo = pd.concat(testzs, ignore_index=True)\n",
    "\n",
    "trainobjectinfo.reset_index(drop=True, inplace=True)\n",
    "testobjectinfo.reset_index(drop=True, inplace=True)\n",
    "\n",
    "del zs\n",
    "del testzs\n",
    "del coorddf\n",
    "del objectCoordinates\n",
    "del objectinfo\n",
    "\n",
    "trainobjects = np.full((len(trainobjectinfo), layersPerObject, objectheight, objectwidth), np.nan)\n",
    "testobjects = np.full((len(testobjectinfo), endlayer-testEnd, objectheight, objectwidth), np.nan)\n",
    "\n",
    "for index, object in trainobjectinfo.iterrows():\n",
    "    trainobjects[index-1] = integrals[object.zstart:object.zend, object.ystart:object.yend, object.xstart:object.xend]\n",
    "for index, object in testobjectinfo.iterrows():\n",
    "    testobjects[index-1] = integrals[object.zstart:object.zend, object.ystart:object.yend, object.xstart:object.xend]\n",
    "\n",
    "aggregate = np.sum(trainobjects, axis=(0,1))\n",
    "\n",
    "aggregate = np.sum(trainobjects, axis=(0,1))\n",
    "\n",
    "emptyRatio = 47\n",
    "limit = np.percentile(aggregate, emptyRatio)\n",
    "backgroundmask = aggregate >= limit\n",
    "# xs = np.copy(aggregate)\n",
    "# xs[~backgroundmask] = np.nan\n",
    "# plt.imshow(xs)\n",
    "# plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors, metrics\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime\n",
    "\n",
    "def preprocess(objects, type, sharpening):\n",
    "    rtn = np.full(objects.shape, np.nan)\n",
    "    # print(rtn.shape)\n",
    "    for index, object in enumerate(objects):\n",
    "        sharpeningKernel = np.array([   [-1, -1,  -1],\n",
    "                                        [-1,  9,  -1],\n",
    "                                        [ -1, -1,  -1]\n",
    "        ]) if sharpening == 'diagonal' else np.array([  [0, -1,  0],\n",
    "                                                        [-1, 5, -1],\n",
    "                                                        [0, -1,  0]])\n",
    "        sharpened = np.array([cv2.filter2D(src=image, ddepth=-1, kernel=sharpeningKernel) for image in object])\n",
    "    # Sharpening is done\n",
    "        if type == 'scatter' or type == 'spatstat':\n",
    "            xs = np.array(sharpened, copy=True, dtype=np.float32)\n",
    "            (endLayer, _, _) = xs.shape\n",
    "            filter = np.repeat([backgroundmask], endLayer, 0)\n",
    "            xs[~filter] = np.nan\n",
    "            rtn[index] = xs\n",
    "        elif type == 'moran':\n",
    "            xs = np.array(sharpened, copy=True, dtype=np.float32)\n",
    "            (endLayer, _, _) = xs.shape\n",
    "            filter = np.repeat([backgroundmask], endLayer, 0)\n",
    "            avg = np.mean(xs, where=filter)\n",
    "            stddev = np.std(xs, where=filter)\n",
    "            xs = (xs - avg) / avg\n",
    "            xs[~filter] = np.nan\n",
    "            rtn[index] = xs\n",
    "    return rtn\n",
    "\n",
    "\n",
    "def calculateoutliers(objects, type, neighbourhoodSetting, windowSize):\n",
    "    c, z, y, x = objects.shape\n",
    "\n",
    "    outlierValues = np.full((c, z + 1 - windowSize, y, x), np.nan)\n",
    "    for index, object in enumerate(objects):\n",
    "        # Step 1: calculate neighbourhood\n",
    "        neighbourkernel = np.array(\n",
    "            [[1, 1, 1],\n",
    "            [1, 1, 1],\n",
    "            [1, 1, 1]]\n",
    "        )/9 if neighbourhoodSetting == 'grid' else np.array(\n",
    "            [[1, 2,  1],\n",
    "            [2, 4, 2],\n",
    "            [1, 2,  1]])/16\n",
    "        flatNeighbourhood = np.array([cv2.filter2D(src=layer, ddepth=-1, kernel=neighbourkernel) for layer in object])\n",
    "        neighbourhoodValues = np.array([\n",
    "            np.sum(flatNeighbourhood[layerIndex-windowSize:layerIndex], axis=0)/windowSize\n",
    "            for layerIndex in range(windowSize, z+1)\n",
    "        ])\n",
    "        # Step 2: calculate outlier\n",
    "        offset = windowSize // 2\n",
    "        endoffset = windowSize - offset - 1\n",
    "\n",
    "        xs = object[offset:z-endoffset]\n",
    "        ys = neighbourhoodValues[0:z-windowSize+1]\n",
    "        filter = np.logical_and(np.isfinite(xs), np.isfinite(ys))\n",
    "\n",
    "        assert(len(set(filter.flatten())) == 2)\n",
    "        if type == 'spatstat':\n",
    "            outliers = xs - ys\n",
    "            avg = np.mean(outliers[filter])\n",
    "            std = np.std(outliers[filter])\n",
    "            outliers = (outliers - avg) / std\n",
    "            outlierValues[index] = outliers\n",
    "        else:\n",
    "            # Is the axis right for moran/scatter?\n",
    "            # print(offset, endoffset, object.shape)\n",
    "            line = np.polyfit(ys[filter].flatten(), xs[filter].flatten(), 1)\n",
    "            p = np.poly1d(line)\n",
    "            outlierValues[index] = xs - p(ys)\n",
    "            assert(outlierValues[index].shape == xs.shape == p(ys).shape)\n",
    "        assert(len(np.unique(outlierValues[index])) > 1)\n",
    "        assert(len(np.unique(np.isfinite(outlierValues[index]))) == 2)\n",
    "    assert(np.average(np.isfinite(outlierValues)) > 0.4)\n",
    "    return outlierValues\n",
    "\n",
    "def encode(outlierobjects, type, buckets, histnormalise, minval=0, maxval=0):\n",
    "    numberOfObjects, _, _, _ = outlierobjects.shape\n",
    "    X = np.full((numberOfObjects, buckets), np.nan)\n",
    "    filter = np.isfinite(outlierobjects)\n",
    "    minval = np.min(outlierobjects[filter]) if minval == 0 else minval\n",
    "    maxval = np.max(outlierobjects[filter]) if maxval == 0 else maxval\n",
    "    for index in range(0, numberOfObjects):\n",
    "        xs = outlierobjects[index]\n",
    "        filter = np.isfinite(xs)\n",
    "        hist, _ = np.histogram(xs[filter], bins=buckets, range=(minval, maxval), density=True)\n",
    "        X[index] = np.array(hist)\n",
    "    \n",
    "    if (histnormalise == 'column'):\n",
    "        X = preprocessing.normalize(X, axis=0)\n",
    "    elif (histnormalise == 'row'):\n",
    "        X = preprocessing.normalize(X, axis=1)\n",
    "    return X, minval, maxval\n",
    "\n",
    "def classify(Xtrain, Ytrain, Xtest, Ytest, n_neighbors):\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=\"distance\")\n",
    "    cvscore = cross_val_score(clf, Xtrain, Ytrain, cv=5, scoring='roc_auc', n_jobs=-1).mean()\n",
    "    clf.fit(Xtrain, Ytrain)\n",
    "    yfit = clf.predict(Xtest)\n",
    "    return cvscore, metrics.roc_auc_score(Ytest, yfit), metrics.precision_score(Ytest, yfit, zero_division=0), metrics.recall_score(Ytest, yfit, zero_division=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweaking parameter settings\n",
    "types = ['moran', 'scatter', 'spatstat']\n",
    "sharpening = ['direct', 'diagonal']\n",
    "windowsizes = range(1, 8, 2)\n",
    "neighbourhoodSetting = ['grid', 'euclidean']\n",
    "buckets = range(30, 151, 30)\n",
    "histnormalise = ('none', 'row')\n",
    "#bucket-lower-limit?\n",
    "k = range(2, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:17:07 Processing type:  moran  sharpening:  direct\n",
      "16:17:10 Processing windowSize:  1  neighbourhood:  grid\n",
      "New highscore:  0.7180451127819549  with settings:      type sharpening  windowSize neighbourhood  buckets histnormalise  \\\n",
      "0  moran     direct           1          grid       30          none   \n",
      "\n",
      "   k-nearest    cv-auc  test-auc  test-precision  test-recall  \n",
      "0          2  0.737321  0.718045        0.428571     0.857143  \n",
      "New highscore:  0.7706766917293233  with settings:      type sharpening  windowSize neighbourhood  buckets histnormalise  \\\n",
      "0  moran     direct           1          grid       30          none   \n",
      "\n",
      "   k-nearest   cv-auc  test-auc  test-precision  test-recall  \n",
      "0          3  0.76179  0.770677             0.5     0.857143  \n",
      "New highscore:  0.7706766917293233  with settings:      type sharpening  windowSize neighbourhood  buckets histnormalise  \\\n",
      "0  moran     direct           1          grid       30          none   \n",
      "\n",
      "   k-nearest    cv-auc  test-auc  test-precision  test-recall  \n",
      "0          4  0.774908  0.770677             0.5     0.857143  \n",
      "New highscore:  0.7706766917293233  with settings:      type sharpening  windowSize neighbourhood  buckets histnormalise  \\\n",
      "0  moran     direct           1          grid       30          none   \n",
      "\n",
      "   k-nearest    cv-auc  test-auc  test-precision  test-recall  \n",
      "0          5  0.785194  0.770677             0.5     0.857143  \n",
      "New highscore:  0.7706766917293233  with settings:      type sharpening  windowSize neighbourhood  buckets histnormalise  \\\n",
      "0  moran     direct           1          grid       30          none   \n",
      "\n",
      "   k-nearest    cv-auc  test-auc  test-precision  test-recall  \n",
      "0          6  0.790728  0.770677             0.5     0.857143  \n",
      "New highscore:  0.7706766917293233  with settings:      type sharpening  windowSize neighbourhood  buckets histnormalise  \\\n",
      "0  moran     direct           1          grid      150          none   \n",
      "\n",
      "   k-nearest    cv-auc  test-auc  test-precision  test-recall  \n",
      "0          6  0.794225  0.770677             0.5     0.857143  \n",
      "New highscore:  0.7706766917293233  with settings:      type sharpening  windowSize neighbourhood  buckets histnormalise  \\\n",
      "0  moran     direct           1          grid      150           row   \n",
      "\n",
      "   k-nearest    cv-auc  test-auc  test-precision  test-recall  \n",
      "0          6  0.794576  0.770677             0.5     0.857143  \n",
      "16:18:05 Processing windowSize:  1  neighbourhood:  euclidean\n",
      "New highscore:  0.8157894736842105  with settings:      type sharpening  windowSize neighbourhood  buckets histnormalise  \\\n",
      "0  moran     direct           1     euclidean       60          none   \n",
      "\n",
      "   k-nearest    cv-auc  test-auc  test-precision  test-recall  \n",
      "0          5  0.799428  0.815789             0.5          1.0  \n",
      "New highscore:  0.8157894736842105  with settings:      type sharpening  windowSize neighbourhood  buckets histnormalise  \\\n",
      "0  moran     direct           1     euclidean       60          none   \n",
      "\n",
      "   k-nearest    cv-auc  test-auc  test-precision  test-recall  \n",
      "0          6  0.799926  0.815789             0.5          1.0  \n",
      "New highscore:  0.744360902255639  with settings:      type sharpening  windowSize neighbourhood  buckets histnormalise  \\\n",
      "0  moran     direct           1     euclidean       90          none   \n",
      "\n",
      "   k-nearest    cv-auc  test-auc  test-precision  test-recall  \n",
      "0          6  0.805378  0.744361        0.461538     0.857143  \n",
      "New highscore:  0.744360902255639  with settings:      type sharpening  windowSize neighbourhood  buckets histnormalise  \\\n",
      "0  moran     direct           1     euclidean       90           row   \n",
      "\n",
      "   k-nearest    cv-auc  test-auc  test-precision  test-recall  \n",
      "0          6  0.806062  0.744361        0.461538     0.857143  \n",
      "16:18:55 Processing windowSize:  3  neighbourhood:  grid\n",
      "16:19:38 Processing windowSize:  3  neighbourhood:  euclidean\n",
      "16:20:21 Processing windowSize:  5  neighbourhood:  grid\n",
      "16:20:58 Processing windowSize:  5  neighbourhood:  euclidean\n",
      "16:21:36 Processing windowSize:  7  neighbourhood:  grid\n",
      "16:22:07 Processing windowSize:  7  neighbourhood:  euclidean\n",
      "16:22:39 Processing type:  moran  sharpening:  diagonal\n",
      "16:22:42 Processing windowSize:  1  neighbourhood:  grid\n",
      "16:23:34 Processing windowSize:  1  neighbourhood:  euclidean\n",
      "16:24:26 Processing windowSize:  3  neighbourhood:  grid\n",
      "16:25:10 Processing windowSize:  3  neighbourhood:  euclidean\n",
      "16:25:54 Processing windowSize:  5  neighbourhood:  grid\n",
      "16:26:31 Processing windowSize:  5  neighbourhood:  euclidean\n",
      "16:27:08 Processing windowSize:  7  neighbourhood:  grid\n",
      "16:27:39 Processing windowSize:  7  neighbourhood:  euclidean\n",
      "16:28:10 Processing type:  scatter  sharpening:  direct\n",
      "16:28:12 Processing windowSize:  1  neighbourhood:  grid\n",
      "New highscore:  0.7894736842105263  with settings:        type sharpening  windowSize neighbourhood  buckets histnormalise  \\\n",
      "0  scatter     direct           1          grid       60          none   \n",
      "\n",
      "   k-nearest    cv-auc  test-auc  test-precision  test-recall  \n",
      "0          5  0.808381  0.789474        0.466667          1.0  \n",
      "New highscore:  0.7894736842105263  with settings:        type sharpening  windowSize neighbourhood  buckets histnormalise  \\\n",
      "0  scatter     direct           1          grid       60          none   \n",
      "\n",
      "   k-nearest    cv-auc  test-auc  test-precision  test-recall  \n",
      "0          6  0.815051  0.789474        0.466667          1.0  \n",
      "New highscore:  0.8157894736842105  with settings:        type sharpening  windowSize neighbourhood  buckets histnormalise  \\\n",
      "0  scatter     direct           1          grid       90          none   \n",
      "\n",
      "   k-nearest    cv-auc  test-auc  test-precision  test-recall  \n",
      "0          5  0.815077  0.815789             0.5          1.0  \n",
      "New highscore:  0.8157894736842105  with settings:        type sharpening  windowSize neighbourhood  buckets histnormalise  \\\n",
      "0  scatter     direct           1          grid       90          none   \n",
      "\n",
      "   k-nearest    cv-auc  test-auc  test-precision  test-recall  \n",
      "0          6  0.822808  0.815789             0.5          1.0  \n",
      "16:29:02 Processing windowSize:  1  neighbourhood:  euclidean\n"
     ]
    }
   ],
   "source": [
    "# Now to tie it all together...\n",
    "columns = ['type', 'sharpening', 'windowSize', 'neighbourhood', 'buckets', 'histnormalise', 'k-nearest', 'cv-auc', 'test-auc', 'test-precision', 'test-recall']\n",
    "results = pd.DataFrame(columns=columns)\n",
    "Ytrain = np.array(trainobjectinfo.loc[:,\"Label\"])\n",
    "Ytest = np.array(testobjectinfo.loc[:,\"Label\"])\n",
    "for type in types:\n",
    "    for sharpSetting in sharpening:\n",
    "        print(datetime.now().strftime(\"%H:%M:%S\"), \"Processing type: \", type, \" sharpening: \", sharpSetting)\n",
    "        # trainpreprocessed = np.apply_along_axis(preprocess, 1, trainobjects, type, sharpSetting)\n",
    "        trainpreprocessed =preprocess(trainobjects, type, sharpSetting)\n",
    "        testpreprocessed =preprocess(testobjects, type, sharpSetting)\n",
    "        for windowsize in windowsizes:\n",
    "            for nSetting in neighbourhoodSetting:\n",
    "                print(datetime.now().strftime(\"%H:%M:%S\"), \"Processing windowSize: \", windowsize, \" neighbourhood: \", nSetting)\n",
    "                # trainoutliers = np.apply_along_axis(calculateoutliers, 1, trainpreprocessed, type, nSetting, windowsize)\n",
    "                trainoutliers = calculateoutliers(trainpreprocessed, type, nSetting, windowsize)\n",
    "                testoutliers = calculateoutliers(testpreprocessed, type, nSetting, windowsize)\n",
    "                \n",
    "                for histnorm in histnormalise:\n",
    "                    for bucket in buckets:\n",
    "                        Xtrain, minval, maxval = encode(trainoutliers, type, bucket, histnorm)\n",
    "                        Xtest, _, _ = encode(testoutliers, type, bucket, histnorm, minval=minval, maxval=maxval)\n",
    "                        # Add encode for test as well\n",
    "                        for n_neighbors in k:\n",
    "                            cvscore, score, precision, recall = classify(Xtrain, Ytrain, Xtest, Ytest, n_neighbors)\n",
    "                            nextRow =  pd.DataFrame([[type, sharpSetting, windowsize, nSetting, bucket, histnorm, n_neighbors, cvscore, score, precision, recall]], columns=columns)\n",
    "                            results = pd.concat([results, nextRow])\n",
    "                        results.to_csv('out9.csv', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug cell\n",
    "\n",
    "type = \"moran\"\n",
    "sharpSetting = \"diagonal\"\n",
    "windowSize = 5\n",
    "histnorm = \"none\"\n",
    "bucket = 30\n",
    "nSetting = \"euclidean\"\n",
    "\n",
    "columns = ['type', 'sharpening', 'windowSize', 'neighbourhood', 'buckets', 'histnormalise', 'k-nearest', 'auc', 'precision', 'recall']\n",
    "results = pd.DataFrame(columns=columns)\n",
    "Ytrain = np.array(trainobjectinfo.loc[:,\"Label\"])\n",
    "Ytest = np.array(testobjectinfo.loc[:,\"Label\"])\n",
    "\n",
    "# Att validera:\n",
    "# Träningsset har flera klasser\n",
    "# Testset har flera klasses\n",
    "# Bilder i varje steg\n",
    "assert(set(Ytest) == set(Ytrain))\n",
    "# trainpreprocessed = np.apply_along_axis(preprocess, 1, trainobjects, type, sharpSetting)\n",
    "trainpreprocessed = preprocess(trainobjects, type, sharpSetting)\n",
    "testpreprocessed = preprocess(testobjects, type, sharpSetting)\n",
    "\n",
    "plt.title(\"training 22 start\")\n",
    "plt.imshow(trainobjects[2][2])\n",
    "plt.figure()\n",
    "plt.title(\"test 22 start\")\n",
    "plt.imshow(testobjects[2][2])\n",
    "plt.figure()\n",
    "plt.title(\"training 22 preprocessed\")\n",
    "plt.imshow(trainpreprocessed[2][2])\n",
    "plt.figure()\n",
    "plt.title(\"test 22 preprocessed\")\n",
    "plt.imshow(testpreprocessed[2][2])\n",
    "plt.figure()\n",
    "# trainoutliers = np.apply_along_axis(calculateoutliers, 1, trainpreprocessed, type, nSetting, windowsize)\n",
    "trainoutliers = calculateoutliers(trainpreprocessed, type, nSetting, windowsize)\n",
    "testoutliers = calculateoutliers(testpreprocessed, type, nSetting, windowsize)\n",
    "print(\"train 2 outliers: \", np.unique(trainoutliers[2]))\n",
    "print(\"test 2 outliers: \", np.unique(testoutliers[2]))\n",
    "print(\"train 1 outliers: \", np.unique(trainoutliers[1]))\n",
    "print(\"test 1 outliers: \", np.unique(testoutliers[1]))\n",
    "plt.title(\"train 22 outliers\")\n",
    "plt.imshow(trainoutliers[2][2])\n",
    "plt.figure()\n",
    "plt.title(\"test 22 outliers\")\n",
    "plt.imshow(testoutliers[2][2])\n",
    "plt.figure()\n",
    "Xtrain, minval, maxval = encode(trainoutliers, type, bucket, histnorm)\n",
    "Xtest, _, _ = encode(testoutliers, type, bucket, histnorm, minval=minval, maxval=maxval)\n",
    "print(\"train 2 outliers: \", np.unique(trainoutliers[2]))\n",
    "print(\"test 2 outliers: \", np.unique(testoutliers[2]))\n",
    "print(\"train 1 outliers: \", np.unique(trainoutliers[1]))\n",
    "print(\"test 1 outliers: \", np.unique(testoutliers[1]))\n",
    "plt.title(\"train 2 outliers\")\n",
    "plt.hist(trainoutliers[2].flatten(), bins=bucket, range=(minval, maxval))\n",
    "plt.yscale('log')\n",
    "plt.figure()\n",
    "plt.title(\"test 2 outliers\")\n",
    "plt.hist(testoutliers[2].flatten(), bins=bucket, range=(minval, maxval))\n",
    "plt.yscale('log')\n",
    "plt.figure()\n",
    "plt.title(\"All outliers\")\n",
    "plt.hist(testoutliers.flatten(), bins=bucket, range=(minval, maxval))\n",
    "plt.yscale('log')\n",
    "plt.figure()\n",
    "# Add encode for test as well\n",
    "for n_neighbors in k:\n",
    "    score, precision, recall = classify(Xtrain, Ytrain, Xtest, Ytest, n_neighbors)\n",
    "    nextRow =  pd.DataFrame([[type, sharpSetting, windowsize, nSetting, bucket, histnorm, n_neighbors, score, precision, recall]], columns=columns)\n",
    "    results = pd.concat([results, nextRow])\n",
    "results.to_csv('out2.csv', index=False, header=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('thesis-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b582782fd74adb665333939d2eb8c9995c52902e0db289bedb880e3a83e2d4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
