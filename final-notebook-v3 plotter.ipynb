{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Notebook plots good settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus cell for using the different test set\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from copy import copy\n",
    "from matplotlib import cm, colors\n",
    "import cv2\n",
    "\n",
    "# Två delar:\n",
    "# 1: fixa segmentstorleken\n",
    "# 2: fixa masker för varje segment\n",
    "# Eller egentligen, skit i det. Applicera masken i förväg?\n",
    "\n",
    "\n",
    "def getTestObjects(porositythreshold=0.5): \n",
    "    objectwidth = 100\n",
    "    objectheight = 100\n",
    "    xspacing = 116\n",
    "    yspacing = 300\n",
    "    xstart = 293\n",
    "    ystart = 445\n",
    "    xend = 1730\n",
    "    yend = 1770\n",
    "    powderthickness = 80\n",
    "    endlayer = 225\n",
    "    vsegments = [0, 150, 187, endlayer]\n",
    "\n",
    "    paths = pathlib.Path('./OT data 80 um/int').glob('*.tif')\n",
    "    paths_sorted = [x for x in paths]\n",
    "    paths_sorted.sort()\n",
    "    integrals = np.array([np.array(plt.imread(path)) for path in paths_sorted])\n",
    "\n",
    "    objectinfo = pd.read_csv('Parameters2.csv', names=[\"Object\", \"P\", \"S\", \"H\", \"Porosity\", \"Label\"])\n",
    "    objectCoordinates = [[x, x+objectwidth, y, y+objectheight] for y in reversed(range(\n",
    "        ystart, yend, objectheight + yspacing)) for x in range(xstart, xend, xspacing + objectwidth)]\n",
    "    coorddf = pd.DataFrame(objectCoordinates, columns=['xstart', 'xend', 'ystart', 'yend'])\n",
    "    objectinfo = coorddf.join(objectinfo)\n",
    "\n",
    "    objectinfo.replace('GOOD', 0, inplace=True)\n",
    "    objectinfo.replace('LOF', 1, inplace=True)\n",
    "    objectinfo.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    objects = np.full((len(objectinfo), endlayer, objectheight, objectwidth), np.nan)\n",
    "\n",
    "    for index, object in objectinfo.iterrows():\n",
    "        objects[index] = integrals[:, object.ystart:object.yend, object.xstart:object.xend]\n",
    "\n",
    "    rtn = np.full(objects.shape, np.nan)\n",
    "    aggregate = np.sum(objects, axis=(0))\n",
    "\n",
    "    emptyRatio = 30\n",
    "    limit = np.percentile(aggregate, emptyRatio)\n",
    "    testmask = aggregate >= limit\n",
    "    for object in objects:\n",
    "        object[~testmask] = np.nan\n",
    "\n",
    "    # Create the good frame\n",
    "    segmentdf = pd.read_csv('Segments2.csv', names=[\"Object\", \"Objectnumber\", \"Segment\", \"P\", \"S\", \"H\", \"Porosity\"])\n",
    "    segmentdf.insert(1, \"VED\", segmentdf.P * 1000/(segmentdf.S * segmentdf.H * powderthickness))\n",
    "    segmentdf.insert(1, \"Label\", np.where(segmentdf.Porosity > porositythreshold, 1, 0))\n",
    "    # segmentdf.drop(segmentdf[(segmentdf.VED > 50)].index, inplace=True)\n",
    "    segmentdf.reset_index(drop=True, inplace=True)\n",
    "    vs = [[vsegments[j], vsegments[j+1]] for i in range(0, len(objects)) for j in reversed(range(0, len(vsegments)-1))]\n",
    "    coorddf = pd.DataFrame(vs, columns=['zstart', 'zend'])\n",
    "    testobjectinfo = coorddf.join(segmentdf)\n",
    "    testobjectinfo.drop(testobjectinfo[(testobjectinfo.Objectnumber == 28) | (testobjectinfo.Objectnumber == 21) ].index, inplace=True)\n",
    "    testobjectinfo.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    testobjects = [objects[object.Objectnumber-1, object.zstart:object.zend] for index, object in testobjectinfo.iterrows()]\n",
    "\n",
    "    del objects\n",
    "    del objectinfo\n",
    "    del coorddf\n",
    "    del objectCoordinates\n",
    "    del paths_sorted\n",
    "    del integrals\n",
    "    print(\"fetching data with \", porositythreshold)\n",
    "    return testobjects, testobjectinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from copy import copy\n",
    "from matplotlib import cm, colors\n",
    "import cv2\n",
    "\n",
    "def getTrainObjects(objectsplit=1, upsamplingratio=1, positive_multiplier=1, porositythreshold=0.5, separate_test=True):\n",
    "    emptyRatio = 47\n",
    "    objectwidth = 83\n",
    "    objectheight = 122\n",
    "    xspacing = 133\n",
    "    yspacing = 270\n",
    "    xstart = 293\n",
    "    ystart = 268\n",
    "    xend = 1730\n",
    "    yend = 1770\n",
    "    hsegments = [0,26,50,74,98,122]\n",
    "    powderthickness = 80\n",
    "    endlayer = 187\n",
    "\n",
    "    paths = pathlib.Path('./OT data 80 um/int').glob('*.tif')\n",
    "    paths_sorted = [x for x in paths]\n",
    "    paths_sorted.sort()\n",
    "    block = np.array([np.array(plt.imread(path)) for path in paths_sorted])\n",
    "    integrals = block[0:endlayer]\n",
    "\n",
    "    del paths_sorted\n",
    "    objectinfo = pd.read_csv('Parameters.csv', names=[\"Object\", \"P\", \"S\", \"H\", \"Porosity\", \"Label\"])\n",
    "\n",
    "    objectCoordinates = [[x, x+objectwidth, y, y+objectheight] for y in reversed(range(\n",
    "        ystart, yend, objectheight + yspacing)) for x in range(xstart, xend, xspacing + objectwidth)]\n",
    "    coorddf = pd.DataFrame(objectCoordinates, columns=['xstart', 'xend', 'ystart', 'yend'])\n",
    "    objectinfo = coorddf.join(objectinfo)\n",
    "\n",
    "    objects = np.full((len(objectinfo), endlayer, objectheight, objectwidth), np.nan)\n",
    "\n",
    "    for index, object in objectinfo.iterrows():\n",
    "        objects[index] = integrals[:, object.ystart:object.yend, object.xstart:object.xend]\n",
    "\n",
    "    aggregate = np.sum(objects, axis=(0,1))\n",
    "\n",
    "    emptyRatio = 47\n",
    "    limit = np.percentile(aggregate, emptyRatio)\n",
    "    mask = aggregate >= limit\n",
    "    mask = np.repeat([mask], endlayer, 0)\n",
    "\n",
    "    for object in objects:\n",
    "        object[~mask] = np.nan\n",
    "\n",
    "    # Time to construct the \"real\" dataframe\n",
    "\n",
    "    segmentdf = pd.read_csv('Segments.csv', names=[\"Object\", \"Objectnumber\", \"Segment\", \"P\", \"S\", \"H\", \"Porosity\", \"Area\"])\n",
    "    segmentdf.insert(1, \"VED\", segmentdf.P * 1000/(segmentdf.S * segmentdf.H * powderthickness))\n",
    "    segmentdf.insert(1, \"Label\", np.where(segmentdf.Porosity > porositythreshold, 1, 0))\n",
    "    originalframe = segmentdf.copy()\n",
    "    hs = [[hsegments[j], hsegments[j+1]] for i in range(0, len(objects)) for j in range(0, len(hsegments)-1)]\n",
    "    coorddf = pd.DataFrame(hs, columns=['hstart', 'hend'])\n",
    "    segmentdf = coorddf.join(segmentdf)\n",
    "\n",
    "    # Start of object multiplication \n",
    "    layersPerObject = endlayer // objectsplit\n",
    "    testEnd = endlayer if separate_test else endlayer - layersPerObject * (objectsplit // 3)\n",
    "    zs = [segmentdf.copy().assign(zstart=z, zend=z+layersPerObject) for z in range(0, testEnd-layersPerObject+1, layersPerObject//(upsamplingratio * positive_multiplier))]\n",
    "    testzs = [segmentdf.copy().assign(zstart=testEnd, zend=endlayer)]\n",
    "    trainobjectinfo = pd.concat(zs, ignore_index=True)\n",
    "    trainobjectinfo.drop(trainobjectinfo[(trainobjectinfo.Objectnumber == 28) | (trainobjectinfo.Objectnumber == 21) ].index, inplace=True)\n",
    "    trainobjectinfo.reset_index(drop=True, inplace=True)\n",
    "    testobjectinfo = pd.concat(testzs, ignore_index=True)\n",
    "\n",
    "    # Removes extra rows \n",
    "    trainobjectinfo = trainobjectinfo[(trainobjectinfo['Label'] == 1) | (trainobjectinfo['zstart'] % (positive_multiplier) == 0)]\n",
    "\n",
    "    trainobjects = [objects[object.Objectnumber-1, object.zstart:object.zend, object.hstart:object.hend] for index, object in trainobjectinfo.iterrows()]\n",
    "    testobjects = [objects[object.Objectnumber-1, object.zstart:object.zend, object.hstart:object.hend] for index, object in testobjectinfo.iterrows()]\n",
    "\n",
    "    print(\"fetching data with objectsplit: {}, upsamplingratio: {}, positive_multiplier: {}, porositythreshold: {}\".format(objectsplit, upsamplingratio, positive_multiplier, porositythreshold))\n",
    "    return trainobjects, trainobjectinfo\n",
    "\n",
    "# assert(np.average(np.isfinite(trainobjects)) == 1)\n",
    "# assert(np.average(np.isfinite(testobjects)) == 1)\n",
    "# xs = np.copy(aggregate)\n",
    "# xs[~backgroundmask] = np.nan\n",
    "# plt.imshow(xs)\n",
    "# plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors, metrics\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn import tree\n",
    "import warnings\n",
    "\n",
    "def preprocess(objects, type, sharpening):\n",
    "    rtn = []\n",
    "    # print(rtn.shape)\n",
    "    for index, object in enumerate(objects):\n",
    "        sharpened = object\n",
    "        if(sharpening != 'none'):\n",
    "            sharpeningKernel = np.array([   [-1, -1,  -1],\n",
    "                                        [-1,  9,  -1],\n",
    "                                        [ -1, -1,  -1]\n",
    "        ]) if sharpening == 'diagonal' else np.array([  [0, -1,  0],\n",
    "                                                        [-1, 5, -1],\n",
    "                                                        [0, -1,  0]])\n",
    "            sharpened = np.array([cv2.filter2D(src=image, ddepth=-1, kernel=sharpeningKernel) for image in object])\n",
    "        # Sharpening is done\n",
    "        if type == 'scatter' or type == 'spatstat':\n",
    "            xs = np.array(sharpened, copy=True, dtype=np.float32)\n",
    "            rtn.append(xs)\n",
    "        elif type == 'moran':\n",
    "            xs = np.array(sharpened, copy=True, dtype=np.float32)\n",
    "            avg = np.nanmean(xs)\n",
    "            stddev = np.nanstd(xs)\n",
    "            xs = (xs - avg) / avg\n",
    "            rtn.append(xs)\n",
    "    return rtn\n",
    "\n",
    "\n",
    "def calculateoutliers(objects, type, neighbourhoodSetting, windowSize):\n",
    "    # c, z, y, x = objects.shape\n",
    "\n",
    "    outlierValues = []\n",
    "    index = 0\n",
    "    # return objects\n",
    "    for object in objects:\n",
    "        z, y, x = object.shape\n",
    "        # Step 1: calculate neighbourhood\n",
    "        neighbourkernel = np.ones((neighbourhoodSetting, neighbourhoodSetting)) / neighbourhoodSetting**2\n",
    "        flatNeighbourhood = np.array([cv2.filter2D(src=layer, ddepth=-1, kernel=neighbourkernel) for layer in object])\n",
    "        neighbourhoodValues = np.array([\n",
    "            np.sum(flatNeighbourhood[layerIndex-windowSize:layerIndex], axis=0)/windowSize\n",
    "            for layerIndex in range(windowSize, z+1)\n",
    "        ])\n",
    "        # Step 2: calculate outlier\n",
    "        offset = windowSize // 2\n",
    "        endoffset = windowSize - offset - 1\n",
    "\n",
    "        ys = neighbourhoodValues[0:z-windowSize+1]\n",
    "        xs = object[offset:z-endoffset]\n",
    "        filter = np.logical_and(np.isfinite(xs), np.isfinite(ys))\n",
    "\n",
    "        # plt.imshow(xs[0])\n",
    "        # plt.figure()\n",
    "        # plt.imshow(xs[0])\n",
    "        # plt.figure()\n",
    "        # if(index == 58):\n",
    "        #     plt.imshow(xs[0])\n",
    "        #     plt.figure()\n",
    "        #     plt.imshow(ys[0])\n",
    "        #     plt.figure()\n",
    "        #     plt.imshow(filter[0])\n",
    "        #     plt.figure()\n",
    "        #     print(len(np.unique(filter)))\n",
    "        numberOfFilterValues = len(np.unique(filter))\n",
    "        # print(\"filterlength is: \", numberOfFilterValues)\n",
    "        # print(\"index is:\", index)\n",
    "        assert numberOfFilterValues == 2, f\"Expected filter to have two values, got: {numberOfFilterValues}\"\n",
    "        if type == 'spatstat':\n",
    "            outliers = xs - ys\n",
    "            avg = np.mean(outliers[filter])\n",
    "            std = np.std(outliers[filter])\n",
    "            outliers = (outliers - avg) / std\n",
    "            outlierValues.append(outliers)\n",
    "        else:\n",
    "            with warnings.catch_warnings():\n",
    "                line = np.polyfit(xs[filter].flatten(), ys[filter].flatten(), 1)\n",
    "                p = np.poly1d(line)\n",
    "                outlierValues.append(p(xs) - ys)\n",
    "            # plt.scatter(xs[filter].flatten(), ys[filter].flatten())\n",
    "            # plt.axline((-0.1, p(-0.1)), (0, p(0)), linewidth=2, color='b')\n",
    "            # plt.figure()\n",
    "            assert(xs.shape == p(ys).shape)\n",
    "        assert(len(np.unique(outlierValues[index])) > 1)\n",
    "        assert(len(np.unique(np.isfinite(outlierValues[index]))) == 2)\n",
    "        index+=1\n",
    "    # print(\"okidk \", np.average(np.isfinite(outlierValues)))\n",
    "    # assert(np.average(np.isfinite(outlierValues)) > 0.4)\n",
    "    return outlierValues\n",
    "\n",
    "def encode(outlierobjects, type, buckets, minval=0, maxval=0, transformer=None):\n",
    "    numberOfObjects = len(outlierobjects)\n",
    "    X = np.full((numberOfObjects, buckets), np.nan)\n",
    "    raw = np.concatenate([oo.flatten() for oo in outlierobjects])\n",
    "    filter = np.isfinite(raw)\n",
    "    minval = np.min(raw[filter]) if minval == 0 else minval\n",
    "    maxval = np.max(raw[filter]) if maxval == 0 else maxval\n",
    "    for index in range(0, numberOfObjects):\n",
    "        xs = outlierobjects[index]\n",
    "        filter = np.isfinite(xs)\n",
    "        hist, edges = np.histogram(xs[filter], bins=buckets, range=(minval, maxval), density=True)\n",
    "        X[index] = np.array(hist)\n",
    "    \n",
    "    return X, minval, maxval, edges, transformer\n",
    "\n",
    "def classify(Xtrain, Ytrain, Xtest, Ytest, n_neighbors, histnormalise):\n",
    "    clf = neighbors.KNeighborsClassifier() if type == 'knn' else RandomForestClassifier()\n",
    "    if (histnormalise == True):\n",
    "        clf = Pipeline([('scaler', StandardScaler()), ('classifier', clf)])\n",
    "    cvs = cross_val_score(clf, Xtrain, Ytrain, cv=10, scoring='roc_auc', n_jobs=-1)\n",
    "    clf.fit(Xtrain, Ytrain)\n",
    "    metrics.plot_roc_curve(clf, Xtest, Ytest) \n",
    "    return [] \n",
    "    # How do we return values for the POD? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter settings\n",
    "types = ['scatter', 'spatstat', 'moran', ]\n",
    "sharpening = ['none', 'direct',]\n",
    "windowsizes = [1, 3, 5, 7]\n",
    "neighbourhoodsize = [3, 5, 7]\n",
    "bins = [5, 10, 20, 40, 80]\n",
    "histnormalise = [True, False]\n",
    "k = [3,5,10,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrow settings for iterating\n",
    "types = ['scatter', 'spatstat', 'moran']\n",
    "sharpening = ['none']\n",
    "windowsizes = [1, 3, 5]\n",
    "neighbourhoodSetting = ['grid']\n",
    "bins = [5,10,20,40]\n",
    "histnormalise = [True, False]\n",
    "k = [5,10,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter settings for the report. Might wanna expand down the line?\n",
    "types = ['scatter', 'spatstat', 'moran']\n",
    "sharpening = ['none']\n",
    "windowsizes = [1, 3, 5, 7]\n",
    "neighbourhoodsize = [3, 5, 7]\n",
    "bins = [5, 10, 20, 40, 80]\n",
    "histnormalise = [True]\n",
    "k = [5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to tie it all together...\n",
    "settingcolumns = ['threshold', 'classifier', 'type', 'z', 'xy', 'bins']\n",
    "settings =  pd.DataFrame([\n",
    "    [0.1, 'KNN', 'moran', 1, 3, 20],\n",
    "    [0.1, 'DT', 'moran', 1, 3, 80],\n",
    "    # ...\n",
    "], columns=settingcolumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to tie it all together...\n",
    "settingcolumns = ['threshold', 'classifier', 'type', 'z', 'xy', 'bins']\n",
    "settings =  pd.DataFrame([\n",
    "    [0.1, 'KNN', 'moran', 1, 3, 20],\n",
    "    [0.1, 'KNN', 'moran', 1, 3, 80],\n",
    "], columns=settingcolumns)\n",
    "\n",
    "def getClassifier (trainobjects, trainobjectinfo, testobjects, testobjectinfo, threshold, classifier, type, z, xy, bins):\n",
    "    sharpSetting = 'none'\n",
    "\n",
    "    Ytrain = np.array(trainobjectinfo.loc[:,\"Label\"])\n",
    "    Ytest = np.array(testobjectinfo.loc[:,\"Label\"])\n",
    "    trainpreprocessed =preprocess(trainobjects, type, sharpSetting)\n",
    "    testpreprocessed =preprocess(testobjects, type, sharpSetting)\n",
    "    print(datetime.now().strftime(\"%H:%M:%S\"), \"Processing windowSize: \", windowsize, \" neighbourhood: \", nSetting)\n",
    "    # trainoutliers = np.apply_along_axis(calculateoutliers, 1, trainpreprocessed, type, nSetting, windowsize)\n",
    "    trainoutliers = calculateoutliers(trainpreprocessed, type, nSetting, windowsize)\n",
    "    testoutliers = calculateoutliers(testpreprocessed, type, nSetting, windowsize)\n",
    "    Xtrain, minval, maxval, edges, transformer = encode(trainoutliers, type, bincount, histnorm)\n",
    "    Xtest, _, _, _, _ = encode(testoutliers, type, bincount, histnorm, minval=minval, maxval=maxval, transformer=transformer)\n",
    "    cvscore, score, precision, recall = classify(Xtrain, Ytrain, Xtest, Ytest, n_neighbors, histnorm)\n",
    "    nextRow =  pd.DataFrame([[type, sharpSetting, windowsize, nSetting, bincount, histnorm, n_neighbors, cvscore, score, precision, recall]], columns=columns)\n",
    "    results = pd.concat([results, nextRow])\n",
    "    results.to_csv(outputfile, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils.file_util import write_file\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import neighbors, metrics\n",
    "from sklearn import tree\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "# Read data\n",
    "\n",
    "# Do the things\n",
    "# Check the baseline\n",
    "# for i in [0.1, 0.25, 0.5]:\n",
    "for i in [0.25]:\n",
    "    # for (objectsplit, upsamplingratio, positive_multiplier) in [(1,1,1), (2,2,2), (2, 1, 2), (3, 3, 3)]:\n",
    "    # for (objectsplit, upsamplingratio, positive_multiplier) in [(1,1,1), (2,2,2)]:\n",
    "    for (objectsplit, upsamplingratio, positive_multiplier) in [(1,1,1)]:\n",
    "    # For each threshold...\n",
    "        testobjects, testobjectinfo = getTestObjects(porositythreshold=i)\n",
    "        trainobjects, trainobjectinfo = getTrainObjects(porositythreshold=i, objectsplit=objectsplit, upsamplingratio=upsamplingratio, positive_multiplier=positive_multiplier, )\n",
    "        # clf = tree.DecisionTreeClassifier(max_depth=1)\n",
    "        # Ytrain = np.array(trainobjectinfo.loc[:,\"Label\"])\n",
    "        # Ytest = np.array(testobjectinfo.loc[:,\"Label\"])\n",
    "        # TrainMean = np.array([np.nanmean(object) for object in trainobjects])\n",
    "        # TestMean = np.array([np.nanmean(object) for object in testobjects])\n",
    "        # clf.fit(TrainMean.reshape(-1, 1), Ytrain)\n",
    "        # Ypred = clf.predict(TestMean.reshape(-1, 1))\n",
    "        # f = open('results/baseline-' + str(i) + '-os-' + str(objectsplit) + '-usr-' + str(upsamplingratio) + '-pm-' + str(positive_multiplier) + '.txt', \"x\")\n",
    "        # f.write(str(metrics.roc_auc_score(Ytest, Ypred)))\n",
    "        # f.close()\n",
    "        doStuff('results/KNN-' + str(i) +  '-os-' + str(objectsplit) + '-usr-' + str(upsamplingratio) + '-pm-' + str(positive_multiplier) + '.csv', trainobjects, trainobjectinfo, testobjects, testobjectinfo)\n",
    "        # We need plots later, but that's fine because we'll plot the good results.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('thesis-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b582782fd74adb665333939d2eb8c9995c52902e0db289bedb880e3a83e2d4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
