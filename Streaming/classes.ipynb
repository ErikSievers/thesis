{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.7.0.72-cp37-abi3-macosx_10_16_x86_64.whl (53.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.9/53.9 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.3 in /Users/erik/anaconda3/lib/python3.10/site-packages (from opencv-python) (1.23.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.7.0.72\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut, train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn import neighbors, metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import copy\n",
    "from matplotlib import cm, colors\n",
    "import cv2\n",
    "import warnings\n",
    "import collections\n",
    "import pathlib\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list of \n",
    "def readRawTreeImages():\n",
    "    objectwidth = 83\n",
    "    objectheight = 122\n",
    "    xspacing = 133\n",
    "    yspacing = 270\n",
    "    xstart = 293\n",
    "    ystart = 268\n",
    "    xend = 1730\n",
    "    yend = 1770\n",
    "    endlayer = 187\n",
    "\n",
    "    paths = pathlib.Path('../OT data 80 um/int').glob('*.tif')\n",
    "    paths_sorted = [x for x in paths]\n",
    "    paths_sorted.sort()\n",
    "    block = np.array([np.array(plt.imread(path)) for path in paths_sorted])\n",
    "    integrals = block[0:endlayer]\n",
    "\n",
    "    del paths_sorted\n",
    "\n",
    "    objectCoordinates = [[x, x+objectwidth, y, y+objectheight] for y in reversed(range(\n",
    "        ystart, yend, objectheight + yspacing)) for x in range(xstart, xend, xspacing + objectwidth)]\n",
    "    coorddf = pd.DataFrame(objectCoordinates, columns=['xstart', 'xend', 'ystart', 'yend'])\n",
    "\n",
    "    objects = np.full((len(coorddf), endlayer, objectheight, objectwidth), np.nan)\n",
    "\n",
    "    for index, object in coorddf.iterrows():\n",
    "        objects[index] = integrals[:, object.ystart:object.yend, object.xstart:object.xend]\n",
    "    \n",
    "    # Removed for eval c\n",
    "    # objects = objects[(np.arange(len(objects))!=20) & (np.arange(len(objects))!=27)]\n",
    "    \n",
    "    return objects\n",
    "\n",
    "def readRawHouseImages():\n",
    "    objectwidth = 100\n",
    "    objectheight = 100\n",
    "    xspacing = 116\n",
    "    yspacing = 300\n",
    "    xstart = 293\n",
    "    ystart = 445\n",
    "    xend = 1730\n",
    "    yend = 1770\n",
    "    powderthickness = 80\n",
    "    endlayer = 225\n",
    "    \n",
    "    paths = pathlib.Path('../OT data 80 um/int').glob('*.tif')\n",
    "    paths_sorted = [x for x in paths]\n",
    "    paths_sorted.sort()\n",
    "    block = np.array([np.array(plt.imread(path)) for path in paths_sorted])\n",
    "    integrals = block[0:endlayer]\n",
    "\n",
    "    del paths_sorted\n",
    "\n",
    "    objectCoordinates = [[x, x+objectwidth, y, y+objectheight] for y in reversed(range(\n",
    "        ystart, yend, objectheight + yspacing)) for x in range(xstart, xend, xspacing + objectwidth)]\n",
    "    coorddf = pd.DataFrame(objectCoordinates, columns=['xstart', 'xend', 'ystart', 'yend'])\n",
    "\n",
    "    objects = np.full((len(coorddf), endlayer, objectheight, objectwidth), np.nan)\n",
    "\n",
    "    for index, object in coorddf.iterrows():\n",
    "        objects[index] = integrals[:, object.ystart:object.yend, object.xstart:object.xend]\n",
    "    \n",
    "    # Removed for eval c\n",
    "    # objects = objects[(np.arange(len(objects))!=20) & (np.arange(len(objects))!=27)]\n",
    "    \n",
    "    return objects\n",
    "\n",
    "def readRawCircles():\n",
    "    mat = scipy.io.loadmat('../OT data 80 um/ot_int_data.mat', simplify_cells=True)\n",
    "    # object, layer, y, x\n",
    "    def sf(obj):\n",
    "        return obj['id']\n",
    "    data = mat.sort(key=sf)\n",
    "    j = 0\n",
    "    objects = []\n",
    "    for i in range(len(data)):\n",
    "        if data[j]['id'] != data[j]['id']:\n",
    "            objects.append()\n",
    "\n",
    "\n",
    "# objects är en 4d numpy array\n",
    "def makeMask(objects, emptyRatio):\n",
    "    aggregate = np.sum(objects, axis=(0,1))\n",
    "    limit = np.percentile(aggregate, emptyRatio)\n",
    "    mask = aggregate >= limit\n",
    "    return mask\n",
    "\n",
    "def getLabels(porositythreshold=0.5):\n",
    "    segmentdf = pd.read_csv('../Segments.csv', names=[\"Object\", \"Objectnumber\", \"Segment\", \"P\", \"S\", \"H\", \"Porosity\", \"Area\"])\n",
    "    \n",
    "    # Removed for eval c\n",
    "    # segmentdf.drop(segmentdf[(segmentdf.Objectnumber == 28) | (segmentdf.Objectnumber == 21) ].index, inplace=True)\n",
    "    # segmentdf.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    segmentdf.insert(1, \"Label\", np.where(segmentdf.Porosity > porositythreshold, 1, 0))\n",
    "    return np.array(segmentdf.loc[:,\"Label\"])\n",
    "\n",
    "def getLabelsB(objectIndex, porositythreshold, startLayer, endLayer):\n",
    "    edges = [0,150,187,225]\n",
    "    segmentdf = pd.read_csv('../Segments2.csv', names=[\"Object\", \"Objectnumber\", \"Segment\", \"P\", \"S\", \"H\", \"Porosity\"])\n",
    "    layers = endLayer - startLayer + 1\n",
    "    s1l = max(0, (min(edges[1], endLayer) - max(edges[0], startLayer)))\n",
    "    s2l = max(0, (min(edges[2], endLayer) - max(edges[1], startLayer)))\n",
    "    s3l = max(0, (min(edges[3], endLayer) - max(edges[2], startLayer)))\n",
    "    porosityvalues = segmentdf.loc[segmentdf.Objectnumber == objectIndex, \"Porosity\"].values\n",
    "    porosity = (porosityvalues[0] * s1l + porosityvalues[1] * s2l + porosityvalues[2] * s3l) / layers\n",
    "    return 1 if porosity >= porositythreshold else 0\n",
    "\n",
    "def makeMaskB(objects, emptyRatio):\n",
    "    # Later, it would be nice to have a more general approach to this\n",
    "    aggregate = np.sum(objects, axis=(0))\n",
    "    limit = np.percentile(aggregate, emptyRatio)\n",
    "    mask = aggregate >= limit\n",
    "    return mask\n",
    "    \n",
    "\n",
    "def classify(Xtrain, Ytrain, Xtest, Ytest, n_neighbors, ):\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=\"uniform\", n_jobs=-1)\n",
    "    scaler = StandardScaler()\n",
    "    clf = Pipeline([('scaler', scaler), ('classifier', clf)])\n",
    "    cvs = cross_val_score(clf, Xtrain, Ytrain, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    clf.fit(Xtrain, Ytrain)\n",
    "    yfit = clf.predict_proba(Xtest)[:,1]\n",
    "    return cvs.mean(), metrics.roc_auc_score(Ytest, yfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scipy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m porositymat \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mloadmat(\u001b[39m'\u001b[39m\u001b[39m../porosity.mat\u001b[39m\u001b[39m'\u001b[39m, simplify_cells\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m porosity \u001b[39m=\u001b[39m porositymat[\u001b[39m'\u001b[39m\u001b[39mporosity\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m1\u001b[39m]\n\u001b[1;32m      3\u001b[0m layermat \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mloadmat(\u001b[39m'\u001b[39m\u001b[39m../layer.mat\u001b[39m\u001b[39m'\u001b[39m, simplify_cells\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scipy' is not defined"
     ]
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "porositymat = scipy.io.loadmat('../porosity.mat', simplify_cells=True)\n",
    "porosity = porositymat['porosity'][1]\n",
    "layermat = scipy.io.loadmat('../layer.mat', simplify_cells=True)\n",
    "layers = layermat['layer'][1]\n",
    "minlayer = np.max([np.min(layers[x]) for x in range(len(layers))])\n",
    "startlayers = np.array([np.min(layers[x]) for x in range(len(layers))], dtype=np.int32) - 1\n",
    "\n",
    "def getLabelsC(objectIndex, porositythreshold, startLayer, endLayer):\n",
    "    porosityvalue = getCporosities(objectIndex, startLayer, endLayer)\n",
    "    return 1 if (porosityvalue*100) >= porositythreshold else 0\n",
    "\n",
    "def getCporosities(objectIndex, startLayer, endLayer):\n",
    "    objectIndex -= 1\n",
    "    layerOffset = startlayers[objectIndex]\n",
    "    if startLayer < layerOffset:\n",
    "        # Might want to change this later, maybe throw an error\n",
    "        startLayer = layerOffset\n",
    "    if endLayer < layerOffset:\n",
    "        endLayer = layerOffset\n",
    "    # print(objectIndex, layerOffset, startLayer, endLayer)\n",
    "    # porosityValue = np.mean(porosity[objectIndex][startLayer-layerOffset:endLayer-layerOffset+1])\n",
    "    porosityValue = np.mean(porosity[objectIndex])\n",
    "    if math.isnan(porosityValue):\n",
    "        raise Exception(\"NaN error in porosity\")\n",
    "    return porosityValue\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSet():\n",
    "    objectwidth = 100\n",
    "    objectheight = 100\n",
    "    xspacing = 260\n",
    "    yspacing = 264\n",
    "    xstart = 235\n",
    "    ystart = 247\n",
    "    xend = 2000\n",
    "    yend = 2000\n",
    "    endlayer = 225\n",
    "\n",
    "    paths = pathlib.Path('../OT data 80 um/Int-validation-2').glob('*.tif')\n",
    "    paths_sorted = [x for x in paths]\n",
    "    paths_sorted.sort()\n",
    "    block = np.array([np.array(plt.imread(path)) for path in paths_sorted])\n",
    "    integrals = block[0:endlayer]\n",
    "    objectCoordinates = [[x, x+objectwidth, y, y+objectheight] for y in reversed(range(\n",
    "    ystart, yend, objectheight + yspacing)) for x in range(xstart, xend, xspacing + objectwidth)]\n",
    "    coorddf = pd.DataFrame(objectCoordinates, columns=['xstart', 'xend', 'ystart', 'yend'])\n",
    "    objects = np.full((len(coorddf), endlayer, objectheight, objectwidth), np.nan)\n",
    "    for index, object in coorddf.iterrows():\n",
    "        objects[index] = integrals[:, object.ystart:object.yend, object.xstart:object.xend]\n",
    "\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using values from Colosimo's dental protheses case study\n",
    "# Constants\n",
    "P_price = 295\n",
    "V = 6*10**-6\n",
    "p = 8300\n",
    "w = 0.05\n",
    "C_operator = 20\n",
    "C_pc = 2.5\n",
    "T_buildprep = 0.5\n",
    "n_p = 8\n",
    "C_lpbfsys = 28\n",
    "C_energy = 0.64\n",
    "C_inertgas = 5\n",
    "C_cut = 2\n",
    "A_baseplate = 0.0625\n",
    "A_part = 2.5*10**-5\n",
    "C_measurement = 0.5\n",
    "\n",
    "# Deterministic parameters\n",
    "# These values need to be adapted\n",
    "alpha = 0\n",
    "beta = 0\n",
    "y = 0\n",
    "\n",
    "# Random parameters (not making them random for reproducibility)\n",
    "CR = 0.5\n",
    "T_setup = 2\n",
    "T_build = 7\n",
    "T_removal = 0.25\n",
    "T_inspection = 0.5\n",
    "C_extra = 8\n",
    "\n",
    "T_proc = T_build\n",
    "T_pre = T_buildprep + T_setup\n",
    "T_post = T_removal + T_inspection\n",
    "\n",
    "# derived values\n",
    "\n",
    "C_material = P_price * V * p*(1+w)\n",
    "C_jobprep = (C_operator + C_pc) * T_buildprep / n_p\n",
    "C_buildprep = C_jobprep\n",
    "C_setup = (C_operator + C_lpbfsys) * T_setup / n_p\n",
    "C_pre = C_jobprep + C_setup\n",
    "\n",
    "# Process cost\n",
    "C_proc = (C_energy + C_inertgas + C_lpbfsys) * T_build / n_p\n",
    "\n",
    "# Post processing cost\n",
    "C_removal = (C_operator + C_lpbfsys) * T_removal / n_p\n",
    "C_basecut = (C_cut / A_baseplate) * A_part\n",
    "C_inspection = (C_operator + C_measurement) * T_inspection \n",
    "C_post = C_removal + C_basecut + C_inspection\n",
    "\n",
    "C_scrap = CR * (C_material + C_proc) + C_pre + C_post\n",
    "C_net = C_material + C_pre + C_proc + C_post\n",
    "C_part = C_net / (1-y)\n",
    "\n",
    "def getCost(scrapRatio, fpr, fnr):\n",
    "    # Recalculate T_build and C_part...\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class backgroundRemover:\n",
    "    def __init__(self, mask):\n",
    "        self.mask = mask\n",
    "        self.layer = 0\n",
    "\n",
    "    def removeBackground(self, images):\n",
    "        rtn = np.copy(images)\n",
    "        if self.mask.ndim > 2:\n",
    "            for o in rtn:\n",
    "                o[~self.mask[self.layer]] = np.nan\n",
    "            self.layer += 1\n",
    "        else:\n",
    "            for o in rtn:\n",
    "                o[~self.mask] = np.nan\n",
    "        return rtn\n",
    "    \n",
    "class blockAccumulator:\n",
    "    def __init__(self, windowSize, windowOffset):\n",
    "        self.ws = windowSize\n",
    "        self.wo = windowOffset\n",
    "        self.init = False\n",
    "        self.currentIndex = 0\n",
    "        self.data = []\n",
    "\n",
    "    def reset(self):\n",
    "        self.init = False\n",
    "        self.currentIndex = 0\n",
    "        self.data = []\n",
    "    \n",
    "    # Nextlayer är ett lager från varje objekt i en lista\n",
    "    def next(self, nextLayer):\n",
    "        for index, objlayer in enumerate(nextLayer):\n",
    "            if not self.init:\n",
    "                (x, y) = np.shape(objlayer)\n",
    "                self.data.append(np.empty((self.ws, x, y)))\n",
    "            self.data[index][self.currentIndex % self.ws] = objlayer\n",
    "        self.currentIndex += 1\n",
    "        self.init = True\n",
    "        if ((self.currentIndex - self.ws) % self.wo == 0 and self.currentIndex >= self.ws):\n",
    "            # Returnera de ws senaste lagren, roterat så att senaste lager ligger sist\n",
    "            return [np.roll(obj, -(self.currentIndex+1 % self.ws), axis=0) for obj in self.data]\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "class accumulator:\n",
    "    def __init__(self, windowSize, windowOffset):\n",
    "        self.ws = windowSize\n",
    "        self.wo = windowOffset\n",
    "        self.data = collections.deque(maxlen=windowSize)\n",
    "        self.currentIndex = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = collections.deque(maxlen=self.ws)\n",
    "        self.currentIndex = 0\n",
    "    \n",
    "    def next(self, nextData):\n",
    "        self.data.append(nextData)\n",
    "        self.currentIndex += 1\n",
    "        if (self.currentIndex % self.wo) == 0:\n",
    "            return np.sum(self.data, axis=0)\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class outlierCalculator:\n",
    "    def __init__(self, type, neighbourhoodDistance, windowSize):\n",
    "        self.type = type\n",
    "        self.nbhd = neighbourhoodDistance\n",
    "        self.ws = windowSize\n",
    "        self.currentLayer = -1\n",
    "        self.init = False\n",
    "\n",
    "    def reset(self):\n",
    "        self.init = False\n",
    "        self.currentLayer = -1\n",
    "\n",
    "    def calculate(self, objects):\n",
    "        outlierValues = []\n",
    "        for idc, objectLayers in enumerate(objects):\n",
    "            objectLayers = np.copy(objectLayers)\n",
    "            if self.type == 'moran':\n",
    "                avg = np.nanmean(objectLayers)\n",
    "                stddev = np.nanstd(objectLayers)\n",
    "                objectLayers = (objectLayers - avg) / stddev\n",
    "            index = 0\n",
    "            z, y, x = objectLayers.shape\n",
    "            # Step 1: calculate neighbourhood\n",
    "            neighbourkernel = np.ones((self.nbhd, self.nbhd)) / self.nbhd**2\n",
    "            flatNeighbourhood = np.array([cv2.filter2D(src=layer, ddepth=-1, kernel=neighbourkernel) for layer in objectLayers])\n",
    "            neighbourhoodValues = np.array([\n",
    "                np.sum(flatNeighbourhood[layerIndex-self.ws:layerIndex], axis=0)/self.ws\n",
    "                for layerIndex in range(self.ws, z+1)\n",
    "            ])\n",
    "            # Step 2: calculate outlier\n",
    "            # This is different from batch processing (we're moving the center)\n",
    "\n",
    "            ys = neighbourhoodValues\n",
    "            xs = objectLayers[self.ws-1:z+1]\n",
    "            filter = np.logical_and(np.isfinite(xs), np.isfinite(ys))\n",
    "\n",
    "            numberOfFilterValues = len(np.unique(filter))\n",
    "            assert numberOfFilterValues == 2, f\"Expected filter to have two values, got: {numberOfFilterValues}\"\n",
    "            if self.type == 'spatstat':\n",
    "                outliers = xs - ys\n",
    "                avg = np.mean(outliers[filter])\n",
    "                std = np.std(outliers[filter])\n",
    "                outliers = (outliers - avg) / std\n",
    "                outlierValues.append(outliers)\n",
    "            else:\n",
    "                with warnings.catch_warnings():\n",
    "                    line = np.polyfit(xs[filter].flatten(), ys[filter].flatten(), 1)\n",
    "                    p = np.poly1d(line)\n",
    "                    outlierValues.append(p(xs) - ys)\n",
    "                assert(xs.shape == p(ys).shape)\n",
    "            assert(len(np.unique(outlierValues[index])) > 1)\n",
    "            assert(len(np.unique(np.isfinite(outlierValues[index]))) == 2)\n",
    "            # if(idc == 0 or idc == 1 or idc == 2):\n",
    "            #     plt.hist(outlierValues[idc][0].flatten())\n",
    "            #     plt.title(\"Histogram of outlier values for object \" + str(idc))\n",
    "            #     plt.figure()\n",
    "        return outlierValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder:\n",
    "    def __init__(self, noOfBins, minval=0, maxval=0):\n",
    "        self.min = minval\n",
    "        self.max = maxval\n",
    "        self.buckets = noOfBins\n",
    "        self.noOfLayers = 0\n",
    "    \n",
    "    # Vad returnerar den här? Ett histogram för hela objektet hittils.\n",
    "    def encode(self, outlierobjects):\n",
    "        self.noOfLayers += 1\n",
    "        numberOfObjects = len(outlierobjects)\n",
    "        # If not locked, store all values and recalculate histogram\n",
    "        # If locked, store only histogramstuff\n",
    "        # What do we emit here? I'd say we emit the complete histogram\n",
    "        # Why raw? What I doing?\n",
    "        returnData = np.zeros((numberOfObjects, self.buckets))\n",
    "        for index in range(0, numberOfObjects):\n",
    "            xs = outlierobjects[index]\n",
    "            filter = np.isfinite(xs)\n",
    "            hist, edges = np.histogram(xs[filter].flatten(), bins=self.buckets, range=(self.min, self.max), density=True)\n",
    "            returnData[index] = hist\n",
    "\n",
    "        return returnData"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
