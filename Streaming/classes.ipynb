{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut, train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn import neighbors, metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import copy\n",
    "from matplotlib import cm, colors\n",
    "import cv2\n",
    "import warnings\n",
    "import collections\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list of \n",
    "def readRawTreeImages():\n",
    "    objectwidth = 83\n",
    "    objectheight = 122\n",
    "    xspacing = 133\n",
    "    yspacing = 270\n",
    "    xstart = 293\n",
    "    ystart = 268\n",
    "    xend = 1730\n",
    "    yend = 1770\n",
    "    endlayer = 187\n",
    "\n",
    "    paths = pathlib.Path('../OT data 80 um/int').glob('*.tif')\n",
    "    paths_sorted = [x for x in paths]\n",
    "    paths_sorted.sort()\n",
    "    block = np.array([np.array(plt.imread(path)) for path in paths_sorted])\n",
    "    integrals = block[0:endlayer]\n",
    "\n",
    "    del paths_sorted\n",
    "\n",
    "    objectCoordinates = [[x, x+objectwidth, y, y+objectheight] for y in reversed(range(\n",
    "        ystart, yend, objectheight + yspacing)) for x in range(xstart, xend, xspacing + objectwidth)]\n",
    "    coorddf = pd.DataFrame(objectCoordinates, columns=['xstart', 'xend', 'ystart', 'yend'])\n",
    "\n",
    "    objects = np.full((len(coorddf), endlayer, objectheight, objectwidth), np.nan)\n",
    "\n",
    "    for index, object in coorddf.iterrows():\n",
    "        objects[index] = integrals[:, object.ystart:object.yend, object.xstart:object.xend]\n",
    "    \n",
    "    objects = objects[(np.arange(len(objects))!=20) & (np.arange(len(objects))!=27)]\n",
    "    \n",
    "    return objects\n",
    "\n",
    "def readRawHouseImages():\n",
    "    objectwidth = 100\n",
    "    objectheight = 100\n",
    "    xspacing = 116\n",
    "    yspacing = 300\n",
    "    xstart = 293\n",
    "    ystart = 445\n",
    "    xend = 1730\n",
    "    yend = 1770\n",
    "    powderthickness = 80\n",
    "    endlayer = 225\n",
    "    \n",
    "    paths = pathlib.Path('../OT data 80 um/int').glob('*.tif')\n",
    "    paths_sorted = [x for x in paths]\n",
    "    paths_sorted.sort()\n",
    "    block = np.array([np.array(plt.imread(path)) for path in paths_sorted])\n",
    "    integrals = block[0:endlayer]\n",
    "\n",
    "    del paths_sorted\n",
    "\n",
    "    objectCoordinates = [[x, x+objectwidth, y, y+objectheight] for y in reversed(range(\n",
    "        ystart, yend, objectheight + yspacing)) for x in range(xstart, xend, xspacing + objectwidth)]\n",
    "    coorddf = pd.DataFrame(objectCoordinates, columns=['xstart', 'xend', 'ystart', 'yend'])\n",
    "\n",
    "    objects = np.full((len(coorddf), endlayer, objectheight, objectwidth), np.nan)\n",
    "\n",
    "    for index, object in coorddf.iterrows():\n",
    "        objects[index] = integrals[:, object.ystart:object.yend, object.xstart:object.xend]\n",
    "    \n",
    "    objects = objects[(np.arange(len(objects))!=20) & (np.arange(len(objects))!=27)]\n",
    "    \n",
    "    return objects\n",
    "\n",
    "# objects 채r en 4d numpy array\n",
    "def makeMask(objects, emptyRatio):\n",
    "    aggregate = np.sum(objects, axis=(0,1))\n",
    "    limit = np.percentile(aggregate, emptyRatio)\n",
    "    mask = aggregate >= limit\n",
    "    return mask\n",
    "\n",
    "def getLabels(porositythreshold=0.5):\n",
    "    segmentdf = pd.read_csv('../Segments.csv', names=[\"Object\", \"Objectnumber\", \"Segment\", \"P\", \"S\", \"H\", \"Porosity\", \"Area\"])\n",
    "    # segmentdf.insert(1, \"VED\", segmentdf.P * 1000/(segmentdf.S * segmentdf.H * powderthickness))\n",
    "    segmentdf.drop(segmentdf[(segmentdf.Objectnumber == 28) | (segmentdf.Objectnumber == 21) ].index, inplace=True)\n",
    "    segmentdf.reset_index(drop=True, inplace=True)\n",
    "    segmentdf.insert(1, \"Label\", np.where(segmentdf.Porosity > porositythreshold, 1, 0))\n",
    "    return np.array(segmentdf.loc[:,\"Label\"])\n",
    "\n",
    "def getLabelsB(objectIndex, porositythreshold, startLayer, endLayer):\n",
    "    edges = [0,150,187,224]\n",
    "    segmentdf = pd.read_csv('../Segments2.csv', names=[\"Object\", \"Objectnumber\", \"Segment\", \"P\", \"S\", \"H\", \"Porosity\"])\n",
    "    layers = endLayer - startLayer + 1\n",
    "    s1l = max(0, (min(edges[1], endLayer) - max(edges[0], startLayer)))\n",
    "    s2l = max(0, (min(edges[2], endLayer) - max(edges[1], startLayer)))\n",
    "    s3l = max(0, (min(edges[3], endLayer) - max(edges[2], startLayer)))\n",
    "    porosityvalues = segmentdf.loc[segmentdf.Objectnumber == objectIndex, \"Porosity\"].values\n",
    "    porosity = (porosityvalues[0] * s1l + porosityvalues[1] * s2l + porosityvalues[2] * s3l) / layers\n",
    "    return 1 if porosity >= porositythreshold else 0\n",
    "\n",
    "def makeMaskB(objects, emptyRatio):\n",
    "    # Later, it would be nice to have a more general approach to this\n",
    "    aggregate = np.sum(objects, axis=(0))\n",
    "    limit = np.percentile(aggregate, emptyRatio)\n",
    "    mask = aggregate >= limit\n",
    "    return mask\n",
    "\n",
    "def classify(Xtrain, Ytrain, Xtest, Ytest, n_neighbors, ):\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=\"uniform\", n_jobs=-1)\n",
    "    scaler = StandardScaler()\n",
    "    clf = Pipeline([('scaler', scaler), ('classifier', clf)])\n",
    "    cvs = cross_val_score(clf, Xtrain, Ytrain, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    clf.fit(Xtrain, Ytrain)\n",
    "    yfit = clf.predict_proba(Xtest)[:,1]\n",
    "    return cvs.mean(), metrics.roc_auc_score(Ytest, yfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(getLabels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class backgroundRemover:\n",
    "    def __init__(self, mask):\n",
    "        self.mask = mask\n",
    "        self.layer = 0\n",
    "\n",
    "    def removeBackground(self, images):\n",
    "        rtn = np.copy(images)\n",
    "        if self.mask.ndim > 2:\n",
    "            for o in rtn:\n",
    "                o[~self.mask[self.layer]] = np.nan\n",
    "            self.layer += 1\n",
    "        else:\n",
    "            for o in rtn:\n",
    "                o[~self.mask] = np.nan\n",
    "        return rtn\n",
    "    \n",
    "class blockAccumulator:\n",
    "    def __init__(self, windowSize, windowOffset):\n",
    "        self.ws = windowSize\n",
    "        self.wo = windowOffset\n",
    "        self.init = False\n",
    "        self.currentIndex = 0\n",
    "        self.data = []\n",
    "\n",
    "    def reset(self):\n",
    "        self.init = False\n",
    "        self.currentIndex = 0\n",
    "        self.data = []\n",
    "    \n",
    "    # Nextlayer 채r ett lager fr책n varje objekt i en lista\n",
    "    def next(self, nextLayer):\n",
    "        for index, objlayer in enumerate(nextLayer):\n",
    "            if not self.init:\n",
    "                (x, y) = np.shape(objlayer)\n",
    "                self.data.append(np.empty((self.ws, x, y)))\n",
    "            self.data[index][self.currentIndex % self.ws] = objlayer\n",
    "        self.currentIndex += 1\n",
    "        self.init = True\n",
    "        if ((self.currentIndex - self.ws) % self.wo == 0 and self.currentIndex >= self.ws):\n",
    "            # Returnera de ws senaste lagren, roterat s책 att senaste lager ligger sist\n",
    "            return [np.roll(obj, -(self.currentIndex+1 % self.ws), axis=0) for obj in self.data]\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "class accumulator:\n",
    "    def __init__(self, windowSize, windowOffset):\n",
    "        self.ws = windowSize\n",
    "        self.wo = windowOffset\n",
    "        self.data = collections.deque(maxlen=windowSize)\n",
    "        self.currentIndex = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = collections.deque(maxlen=self.ws)\n",
    "        self.currentIndex = 0\n",
    "    \n",
    "    def next(self, nextData):\n",
    "        self.data.append(nextData)\n",
    "        self.currentIndex += 1\n",
    "        if (self.currentIndex % self.wo) == 0:\n",
    "            return np.sum(self.data, axis=0)\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class outlierCalculator:\n",
    "    def __init__(self, type, neighbourhoodDistance, windowSize):\n",
    "        self.type = type\n",
    "        self.nbhd = neighbourhoodDistance\n",
    "        self.ws = windowSize\n",
    "        self.currentLayer = -1\n",
    "        self.init = False\n",
    "\n",
    "    def reset(self):\n",
    "        self.init = False\n",
    "        self.currentLayer = -1\n",
    "\n",
    "    def calculate(self, objects):\n",
    "        outlierValues = []\n",
    "        for idc, objectLayers in enumerate(objects):\n",
    "            objectLayers = np.copy(objectLayers)\n",
    "            if self.type == 'moran':\n",
    "                avg = np.nanmean(objectLayers)\n",
    "                stddev = np.nanstd(objectLayers)\n",
    "                objectLayers = (xs - avg) / stddev\n",
    "            index = 0\n",
    "            z, y, x = objectLayers.shape\n",
    "            # Step 1: calculate neighbourhood\n",
    "            neighbourkernel = np.ones((self.nbhd, self.nbhd)) / self.nbhd**2\n",
    "            flatNeighbourhood = np.array([cv2.filter2D(src=layer, ddepth=-1, kernel=neighbourkernel) for layer in objectLayers])\n",
    "            neighbourhoodValues = np.array([\n",
    "                np.sum(flatNeighbourhood[layerIndex-self.ws:layerIndex], axis=0)/self.ws\n",
    "                for layerIndex in range(self.ws, z+1)\n",
    "            ])\n",
    "            # Step 2: calculate outlier\n",
    "            # This is different from batch processing (we're moving the center)\n",
    "\n",
    "            ys = neighbourhoodValues\n",
    "            xs = objectLayers[self.ws-1:z+1]\n",
    "            filter = np.logical_and(np.isfinite(xs), np.isfinite(ys))\n",
    "\n",
    "            numberOfFilterValues = len(np.unique(filter))\n",
    "            assert numberOfFilterValues == 2, f\"Expected filter to have two values, got: {numberOfFilterValues}\"\n",
    "            if self.type == 'spatstat':\n",
    "                outliers = xs - ys\n",
    "                avg = np.mean(outliers[filter])\n",
    "                std = np.std(outliers[filter])\n",
    "                outliers = (outliers - avg) / std\n",
    "                outlierValues.append(outliers)\n",
    "            else:\n",
    "                with warnings.catch_warnings():\n",
    "                    line = np.polyfit(xs[filter].flatten(), ys[filter].flatten(), 1)\n",
    "                    p = np.poly1d(line)\n",
    "                    outlierValues.append(p(xs) - ys)\n",
    "                assert(xs.shape == p(ys).shape)\n",
    "            assert(len(np.unique(outlierValues[index])) > 1)\n",
    "            assert(len(np.unique(np.isfinite(outlierValues[index]))) == 2)\n",
    "            # if(idc == 0 or idc == 1 or idc == 2):\n",
    "            #     plt.hist(outlierValues[idc][0].flatten())\n",
    "            #     plt.title(\"Histogram of outlier values for object \" + str(idc))\n",
    "            #     plt.figure()\n",
    "        return outlierValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder:\n",
    "    def __init__(self, noOfBins, minval=0, maxval=0):\n",
    "        self.min = minval\n",
    "        self.max = maxval\n",
    "        self.buckets = noOfBins\n",
    "        self.noOfLayers = 0\n",
    "    \n",
    "    # Vad returnerar den h채r? Ett histogram f철r hela objektet hittils.\n",
    "    def encode(self, outlierobjects):\n",
    "        self.noOfLayers += 1\n",
    "        numberOfObjects = len(outlierobjects)\n",
    "        # If not locked, store all values and recalculate histogram\n",
    "        # If locked, store only histogramstuff\n",
    "        # What do we emit here? I'd say we emit the complete histogram\n",
    "        # Why raw? What I doing?\n",
    "        returnData = np.zeros((numberOfObjects, self.buckets))\n",
    "        for index in range(0, numberOfObjects):\n",
    "            xs = outlierobjects[index]\n",
    "            filter = np.isfinite(xs)\n",
    "            hist, edges = np.histogram(xs[filter].flatten(), bins=self.buckets, range=(self.min, self.max), density=True)\n",
    "            returnData[index] = hist\n",
    "\n",
    "        return returnData"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
