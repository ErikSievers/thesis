{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut, train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn import neighbors, metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import copy\n",
    "from matplotlib import cm, colors\n",
    "import cv2\n",
    "import warnings\n",
    "import collections\n",
    "\n",
    "\n",
    "# Takes a 2D numpy array as input (i.e. a numpy representation of an image)\n",
    "# Different from tree since the empty ratio is different. Could implement a generic\n",
    "# solution down the line\n",
    "def processNextHouseImage(image): \n",
    "    objectwidth = 100\n",
    "    objectheight = 100\n",
    "    xspacing = 116\n",
    "    yspacing = 300\n",
    "    xstart = 293\n",
    "    ystart = 445\n",
    "    xend = 1730\n",
    "    yend = 1770\n",
    "    powderthickness = 80\n",
    "    objectCoordinates = [[x, x+objectwidth, y, y+objectheight] for y in reversed(range(\n",
    "        ystart, yend, objectheight + yspacing)) for x in range(xstart, xend, xspacing + objectwidth)]\n",
    "    # Rest NYI\n",
    "\n",
    "# Returns a list of images of each object, with the background filtered out\n",
    "def processNextTreeImage(image):\n",
    "    objectwidth = 83\n",
    "    objectheight = 122\n",
    "    xspacing = 133\n",
    "    yspacing = 270\n",
    "    xstart = 293\n",
    "    ystart = 268\n",
    "    xend = 1730\n",
    "    yend = 1770\n",
    "\n",
    "    # objectinfo = pd.read_csv('Parameters.csv', names=[\"Object\", \"P\", \"S\", \"H\", \"Porosity\", \"Label\"])\n",
    "\n",
    "    objectCoordinates = [[x, x+objectwidth, y, y+objectheight] for y in reversed(range(\n",
    "        ystart, yend, objectheight + yspacing)) for x in range(xstart, xend, xspacing + objectwidth)]\n",
    "    # coorddf = pd.DataFrame(objectCoordinates, columns=['xstart', 'xend', 'ystart', 'yend'])\n",
    "    # objectinfo = coorddf.join(objectinfo)\n",
    "\n",
    "    objects = np.full((len(objectCoordinates), objectheight, objectwidth), np.nan)\n",
    "\n",
    "    for index, object in objectCoordinates.iterrows():\n",
    "        objects[index] = image[object.ystart:object.yend, object.xstart:object.xend]\n",
    "\n",
    "    # for object in objects:\n",
    "    #     object[~mask] = np.nan\n",
    "\n",
    "    return objects\n",
    "\n",
    "class backgroundRemover:\n",
    "    def __init__(self, mask):\n",
    "        self.mask = mask\n",
    "\n",
    "    def removeBackground(self, images):\n",
    "        for object in images:\n",
    "            object[~self.mask] = np.nan\n",
    "        return images\n",
    "\n",
    "# Conducts preprocessing. OldObjectLayers is a list of objects, with each object being a 3d numpy array\n",
    "\n",
    "class preprocessor:\n",
    "    def __init__(self, type, noOfObjects, x, y, z):\n",
    "        self.type = type\n",
    "        # self.accumulatedLayers = [np.empty((z, y, x))]  * noOfObjects\n",
    "        self.currentLayer = -1\n",
    "\n",
    "    def preprocess(self, newObjectLayers):\n",
    "        self.currentLayer += 1\n",
    "        # layerIndex = self.currentLayer\n",
    "        returnValue = []\n",
    "        for index, object in enumerate(newObjectLayers):\n",
    "            if self.type == 'scatter' or self.type == 'spatstat':\n",
    "                object = np.copy(object)\n",
    "                xs = np.array(object, copy=True, dtype=np.float32)\n",
    "                # self.accumulatedLayers[index][layerIndex] = xs\n",
    "                returnValue.append(xs)\n",
    "            elif self.type == 'moran':\n",
    "                # Todo: consider revising and not doing on a layer-by-layer basis?\n",
    "                xs = np.array(object, copy=True, dtype=np.float32)\n",
    "                avg = np.nanmean(xs)\n",
    "                stddev = np.nanstd(xs)\n",
    "                xs = (xs - avg) / stddev\n",
    "                # self.accumulatedLayers[index][layerIndex] = xs\n",
    "                returnValue.append(xs)\n",
    "        return returnValue\n",
    "\n",
    "class outlierCalculator:\n",
    "    def __init__(self, type, neighbourhoodDistance, windowSize, noOfObjects, x, y, z):\n",
    "        self.type = type\n",
    "        self.nbhd = neighbourhoodDistance\n",
    "        self.ws = windowSize\n",
    "        self.shape = (z, y, x)\n",
    "        self.currentLayer = -1\n",
    "        self.noOfObjects = noOfObjects\n",
    "        self.init = False\n",
    "\n",
    "    def reset(self):\n",
    "        self.init = False\n",
    "        self.currentLayer = -1\n",
    "\n",
    "    def calculate(self, newObjectLayers):\n",
    "        self.currentLayer += 1\n",
    "        outlierValues = []\n",
    "        if not self.init:\n",
    "            self.init = True\n",
    "            self.accumulatedLayers = [np.empty(self.shape)]  * self.noOfObjects\n",
    "        for index, objectLayer in enumerate(newObjectLayers):\n",
    "            # Step 1: calculate neighbourhood\n",
    "            object = np.copy(objectLayer)\n",
    "            neighbourkernel = np.ones((self.nbhd, self.nbhd)) / self.nbhd**2\n",
    "            flatNeighbourhood = np.array(cv2.filter2D(src=objectLayer, ddepth=-1, kernel=neighbourkernel))\n",
    "            self.accumulatedLayers[index][self.currentLayer] = flatNeighbourhood\n",
    "\n",
    "            if(self.currentLayer+1 < self.ws):\n",
    "                print(\"no result yet\")\n",
    "                return outlierValues\n",
    "            step1 = self.accumulatedLayers[index][self.currentLayer-(self.ws-1):self.currentLayer+1]\n",
    "\n",
    "            step2 = np.sum(step1, axis=0)\n",
    "            neighbourhoodValues = step2 / self.ws\n",
    "            # Här har vi tre saker att hålla koll på:\n",
    "            # - Nästa lager\n",
    "            # - Tidigare lager som del av beräkningen\n",
    "            # - Tidigare lagers neighbourhoodvalues (eller, varför?)\n",
    "            # Vi vill returnera fler neighbourhoodvalues baserat på lagret som kom in... skit i tidigare, de poolas längre ned.\n",
    "\n",
    "            # Step 2: calculate outlier\n",
    "            ys = neighbourhoodValues\n",
    "            xs = object\n",
    "            filter = np.logical_and(np.isfinite(xs), np.isfinite(ys))\n",
    "\n",
    "            # plt.imshow(xs[0])\n",
    "            # plt.figure()\n",
    "            # plt.imshow(xs[0])\n",
    "            # plt.figure()\n",
    "            # if(index == 58):\n",
    "            #     plt.imshow(xs[0])\n",
    "            #     plt.figure()\n",
    "            #     plt.imshow(ys[0])\n",
    "            #     plt.figure()\n",
    "            #     plt.imshow(filter[0])\n",
    "            #     plt.figure()\n",
    "            #     print(len(np.unique(filter)))\n",
    "            numberOfFilterValues = len(np.unique(filter))\n",
    "            assert numberOfFilterValues == 2, f\"Expected filter to have two values, got: {numberOfFilterValues}\"\n",
    "            # print(\"filterlength is: \", numberOfFilterValues)\n",
    "            # print(\"index is:\", index)\n",
    "            if type == 'spatstat':\n",
    "                outliers = xs - ys\n",
    "                avg = np.mean(outliers[filter])\n",
    "                std = np.std(outliers[filter])\n",
    "                outliers = (outliers - avg) / std\n",
    "                outlierValues.append(outliers)\n",
    "            else:\n",
    "                with warnings.catch_warnings():\n",
    "                    line = np.polyfit(xs[filter].flatten(), ys[filter].flatten(), 1)\n",
    "                    p = np.poly1d(line)\n",
    "                    outlierValues.append(p(xs) - ys)\n",
    "                assert(xs.shape == p(ys).shape)\n",
    "            assert(len(np.unique(outlierValues[index])) > 1)\n",
    "            assert(len(np.unique(np.isfinite(outlierValues[index]))) == 2)\n",
    "        return outlierValues\n",
    "\n",
    "class encoder:\n",
    "    def __init__(self, noOfBins, minval=0, maxval=0):\n",
    "        self.min = minval\n",
    "        self.max = maxval\n",
    "        self.buckets = noOfBins\n",
    "        # self.X = np.full((noOfObjects, noOfBins), np.nan)\n",
    "        # self.data = np.full((noOfObjects, 0), 0)\n",
    "        self.X = False\n",
    "        self.data = False\n",
    "        self.noOfLayers = 0\n",
    "        self.locked = False\n",
    "        self.init = False\n",
    "    \n",
    "    def lockAndReset(self):\n",
    "        self.locked = True\n",
    "        self.X = False\n",
    "        self.init = False\n",
    "    \n",
    "    # Vad returnerar den här? Ett histogram för hela objektet hittils.\n",
    "    def encode(self, outlierobjects):\n",
    "        self.noOfLayers += 1\n",
    "        numberOfObjects = len(outlierobjects)\n",
    "        # If not locked, store all values and recalculate histogram\n",
    "        # If locked, store only histogramstuff\n",
    "        # What do we emit here? I'd say we emit the complete histogram\n",
    "        # Why raw? What I doing?\n",
    "        returnData = np.zeros((numberOfObjects, self.buckets))\n",
    "        for index in range(0, numberOfObjects):\n",
    "            xs = outlierobjects[index]\n",
    "            filter = np.isfinite(xs)\n",
    "            hist, edges = np.histogram(xs[filter], bins=self.buckets, range=(self.min, self.max), density=True)\n",
    "            returnData[index] = hist\n",
    "\n",
    "        return returnData\n",
    "    \n",
    "class accumulator:\n",
    "    def __init__(self, windowSize, windowOffset):\n",
    "        self.ws = windowSize\n",
    "        self.wo = windowOffset\n",
    "        self.data = collections.deque(maxlen=windowSize)\n",
    "        self.currentIndex = 0\n",
    "    \n",
    "    def next(self, nextData):\n",
    "        self.data.append(nextData)\n",
    "        self.currentIndex += 1\n",
    "        if (self.currentIndex % self.wo) == 0:\n",
    "            return np.sum(self.data, axis=0)\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    \n",
    "\n",
    "def classify(Xtrain, Ytrain, Xtest, Ytest, n_neighbors, ):\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=\"uniform\", n_jobs=-1)\n",
    "    scaler = StandardScaler()\n",
    "    clf = Pipeline([('scaler', scaler), ('classifier', clf)])\n",
    "    cvs = cross_val_score(clf, Xtrain, Ytrain, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    clf.fit(Xtrain, Ytrain)\n",
    "    yfit = clf.predict_proba(Xtest)[:,1]\n",
    "    return cvs.mean(), metrics.roc_auc_score(Ytest, yfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "# Returns a list of \n",
    "def readRawTreeImages():\n",
    "    objectwidth = 83\n",
    "    objectheight = 122\n",
    "    xspacing = 133\n",
    "    yspacing = 270\n",
    "    xstart = 293\n",
    "    ystart = 268\n",
    "    xend = 1730\n",
    "    yend = 1770\n",
    "    endlayer = 187\n",
    "\n",
    "    paths = pathlib.Path('./OT data 80 um/int').glob('*.tif')\n",
    "    paths_sorted = [x for x in paths]\n",
    "    paths_sorted.sort()\n",
    "    block = np.array([np.array(plt.imread(path)) for path in paths_sorted])\n",
    "    integrals = block[0:endlayer]\n",
    "\n",
    "    del paths_sorted\n",
    "\n",
    "    objectCoordinates = [[x, x+objectwidth, y, y+objectheight] for y in reversed(range(\n",
    "        ystart, yend, objectheight + yspacing)) for x in range(xstart, xend, xspacing + objectwidth)]\n",
    "    coorddf = pd.DataFrame(objectCoordinates, columns=['xstart', 'xend', 'ystart', 'yend'])\n",
    "\n",
    "    objects = np.full((len(coorddf), endlayer, objectheight, objectwidth), np.nan)\n",
    "\n",
    "    for index, object in coorddf.iterrows():\n",
    "        objects[index] = integrals[:, object.ystart:object.yend, object.xstart:object.xend]\n",
    "    \n",
    "    return objects\n",
    "\n",
    "# objects är en 4d numpy array\n",
    "def makeMask(objects, emptyRatio):\n",
    "    aggregate = np.sum(objects, axis=(0,1))\n",
    "    limit = np.percentile(aggregate, emptyRatio)\n",
    "    mask = aggregate >= limit\n",
    "    return mask\n",
    "\n",
    "def getLabels():\n",
    "    objectinfo = pd.read_csv('Parameters.csv', names=[\"Object\", \"P\", \"S\", \"H\", \"Porosity\", \"Label\"])\n",
    "    objectinfo.replace('GOOD', 0, inplace=True)\n",
    "    objectinfo.replace('LOF', 1, inplace=True)\n",
    "    return np.array(objectinfo.loc[:,\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Training cell\n",
    "\n",
    "# High level picture\n",
    "# We can batch prepare\n",
    "\n",
    "# Start with the training\n",
    "emptyRatio = 47\n",
    "objectwidth = 83\n",
    "objectheight = 122\n",
    "layers = 187\n",
    "\n",
    "odtype = 'spatstat'\n",
    "neighbourhoodDistance = 5\n",
    "neighbourhoodZ = 1\n",
    "windowSize = 60\n",
    "windowOffset = 30\n",
    "noOfObjects = 28\n",
    "noOfBins = 20\n",
    "n_neighbors = 3\n",
    "mask = np.zeros((objectwidth, objectheight))\n",
    "\n",
    "allImages = readRawTreeImages()\n",
    "allImages = allImages[(np.arange(len(allImages))!=20) & (np.arange(len(allImages))!=27)]\n",
    "labels = getLabels()\n",
    "labels = labels[(np.arange(len(labels))!=20) & (np.arange(len(labels))!=27)]\n",
    "X_train, X_test, y_train, y_test = train_test_split(allImages, labels, test_size=0.40)\n",
    "# trainObjects = allImages[[1,2,3,5,6,8,9,11,12,14,15,17,18,21,23,24,26], :, :, :]\n",
    "# testObjects = allImages[[0,4,7,10,13,16,19,22,25], :, :, :]\n",
    "\n",
    "# testMask = np.array([1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,0])\n",
    "# trainMask = testMask == 0\n",
    "# trainMask[20] = False\n",
    "# trainMask[27] = False\n",
    "# ytrain = np.extract(trainMask, labels)\n",
    "# ytest = np.extract(testMask, labels)\n",
    "mask = makeMask(X_train, emptyRatio)\n",
    "\n",
    "\n",
    "bgr = backgroundRemover(mask)\n",
    "p1 = preprocessor(odtype, noOfObjects, objectwidth, objectheight, layers)\n",
    "oc1 = outlierCalculator(odtype, neighbourhoodDistance, neighbourhoodZ, noOfObjects, objectwidth, objectheight, layers)\n",
    "a1 = accumulator(windowSize, windowOffset)\n",
    "\n",
    "\n",
    "# Hur skapar vi masken? Vad är lättast?\n",
    "# Dela inläsningen i två steg: en som bara delar, en som tar bort bakgrund. Skicka mask som input till dess constructor\n",
    "\n",
    "\n",
    "allTrainingHists = []\n",
    "\n",
    "# images är en lista av bildstackar?\n",
    "# hur gör vi splitten här?\n",
    "# - per föremål\n",
    "# - per segment\n",
    "# - per både våg- och horizontella segment\n",
    "# Med all sannolikhet kommer vi ändra det senare, eller fokusera på att lära mellan geometrier\n",
    "# lägst effort: lägg åt sidan 28*0.33 objekt som inte är med för att ha en prototyp uppe\n",
    "# högst intresse: använd alla trädbilder för träning, använd alla husbilder för utvärdering, sätt automatisk gräns för\n",
    "# bakgrund mha typ clustering\n",
    "# medelväg: behandla bakgrundseliminering utanför streamingapproachen\n",
    "# OK, steg 1: enbart träd. Ta 0.33 av dem och bara sätt åt sidan. Välj vilka själv. Så images är en lista av bilder...\n",
    "\n",
    "# Ändra indexering ifrån [objektnummber, lager, x, y] till [lager, objektnummer, x, y]\n",
    "trainObjects = np.moveaxis(X_train, 1, 0)\n",
    "testObjects = np.moveaxis(X_test, 1, 0)\n",
    "\n",
    "allOcvals = []\n",
    "for image in trainObjects:\n",
    "    # Ta bilden, omvandla till en array av bilder (en bild per obj)\n",
    "    # Vilken struktur behöver preprocess? Lista med numpy array\n",
    "    noback = bgr.removeBackground(image)\n",
    "    pres = p1.preprocess(noback)\n",
    "    ocvals = oc1.calculate(pres)\n",
    "    allOcvals.append(ocvals)\n",
    "\n",
    "ocmin = np.nanmin(allOcvals)\n",
    "ocmax = np.nanmax(allOcvals)\n",
    "e1 = encoder(noOfBins, ocmin, ocmax)\n",
    "\n",
    "for ocvals in allOcvals:\n",
    "    if len(ocvals) > 0:\n",
    "        hists = e1.encode(ocvals)\n",
    "        accs = a1.next(hists)\n",
    "        if type(accs) is np.ndarray:\n",
    "            for acc in accs:\n",
    "                allTrainingHists.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;classifier&#x27;, KNeighborsClassifier(n_jobs=-1, n_neighbors=3))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;classifier&#x27;, KNeighborsClassifier(n_jobs=-1, n_neighbors=3))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_jobs=-1, n_neighbors=3)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('classifier', KNeighborsClassifier(n_jobs=-1, n_neighbors=3))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repetitions = len(allTrainingHists) / len(y_train)\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors, weights=\"uniform\", n_jobs=-1)\n",
    "scaler = StandardScaler()\n",
    "clf = Pipeline([('scaler', scaler), ('classifier', clf)])\n",
    "ytrain2 = np.tile(y_train.astype('int'), [np.int32(repetitions)])\n",
    "clf.fit(allTrainingHists, ytrain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3125\n"
     ]
    }
   ],
   "source": [
    "# Testing cell\n",
    "from sklearn.metrics import f1_score\n",
    "e1.lockAndReset()\n",
    "oc1.reset()\n",
    "y_test = y_test.astype('int')\n",
    "\n",
    "testx = []\n",
    "predictions = []\n",
    "for image in testObjects:\n",
    "    # Start of timing\n",
    "    plt.imshow(image[0])\n",
    "    plt.title(\"background 0\")\n",
    "    plt.figure()\n",
    "    noback = bgr.removeBackground(image)\n",
    "    plt.imshow(noback[0])\n",
    "    plt.title(\"nobackground 0\")\n",
    "    plt.figure()\n",
    "    pres = p1.preprocess(noback)\n",
    "    ocvals = oc1.calculate(pres)\n",
    "    if len(ocvals) > 0:\n",
    "        hists = e1.encode(ocvals)\n",
    "        pred = clf.predict(hists)\n",
    "        # End of timing\n",
    "        testx.append(hists)\n",
    "        predictions.append(pred)\n",
    "        break;\n",
    "\n",
    "# investigate accuracy etc here. Potentially batch it based on layer\n",
    "for index, o in enumerate(predictions):\n",
    "    if len(np.unique(o)) > 1:\n",
    "        print(f1_score(y_test, o, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b582782fd74adb665333939d2eb8c9995c52902e0db289bedb880e3a83e2d4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
