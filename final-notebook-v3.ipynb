{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the other object as test set ðŸ¤ª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus cell for using the different test set\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from copy import copy\n",
    "from matplotlib import cm, colors\n",
    "import cv2\n",
    "\n",
    "objectwidth = 100\n",
    "objectheight = 100\n",
    "xspacing = 116\n",
    "yspacing = 300\n",
    "xstart = 293\n",
    "ystart = 445\n",
    "xend = 1730\n",
    "yend = 1770\n",
    "powderthickness = 80\n",
    "endlayer = 225\n",
    "\n",
    "paths = pathlib.Path('./OT data 80 um/int').glob('*.tif')\n",
    "paths_sorted = [x for x in paths]\n",
    "paths_sorted.sort()\n",
    "integrals = np.array([np.array(plt.imread(path)) for path in paths_sorted])\n",
    "\n",
    "objectinfo = pd.read_csv('Parameters2.csv', names=[\"Object\", \"P\", \"S\", \"H\", \"Porosity\", \"Label\"])\n",
    "objectinfo.insert(1, \"VED\", objectinfo.P * 1000/(objectinfo.S * objectinfo.H * powderthickness))\n",
    "objectCoordinates = [[x, x+objectwidth, y, y+objectheight] for y in reversed(range(\n",
    "    ystart, yend, objectheight + yspacing)) for x in range(xstart, xend, xspacing + objectwidth)]\n",
    "coorddf = pd.DataFrame(objectCoordinates, columns=['xstart', 'xend', 'ystart', 'yend'])\n",
    "objectinfo = coorddf.join(objectinfo)\n",
    "\n",
    "del coorddf\n",
    "del objectCoordinates\n",
    "del paths_sorted\n",
    "\n",
    "objectinfo.drop(objectinfo[objectinfo.Label == 'KH'].index, inplace=True)\n",
    "objectinfo.replace('GOOD', 0, inplace=True)\n",
    "objectinfo.replace('LOF', 1, inplace=True)\n",
    "objectinfo.reset_index(drop=True, inplace=True)\n",
    "\n",
    "objects = np.full((len(objectinfo), endlayer, objectheight, objectwidth), np.nan)\n",
    "\n",
    "for index, object in objectinfo.iterrows():\n",
    "    objects[index] = integrals[:, object.ystart:object.yend, object.xstart:object.xend]\n",
    "del integrals\n",
    "\n",
    "aggregate = np.sum(objects, axis=(0))\n",
    "\n",
    "emptyRatio = 30\n",
    "limit = np.percentile(aggregate, emptyRatio)\n",
    "testmask = aggregate >= limit\n",
    "\n",
    "testobjects = objects\n",
    "testobjectinfo = objectinfo\n",
    "del objects\n",
    "del objectinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train data\n",
    "\n",
    "emptyRatio = 47\n",
    "objectwidth = 83\n",
    "objectheight = 122\n",
    "xspacing = 133\n",
    "yspacing = 270\n",
    "xstart = 293\n",
    "ystart = 268\n",
    "xend = 1730\n",
    "yend = 1770\n",
    "powderthickness = 80\n",
    "endlayer = 187\n",
    "\n",
    "paths = pathlib.Path('./OT data 80 um/int').glob('*.tif')\n",
    "paths_sorted = [x for x in paths]\n",
    "paths_sorted.sort()\n",
    "block = np.array([np.array(plt.imread(path)) for path in paths_sorted])\n",
    "integrals = block[0:endlayer]\n",
    "\n",
    "del paths_sorted\n",
    "objectinfo = pd.read_csv('Parameters.csv', names=[\"Object\", \"P\", \"S\", \"H\", \"Porosity\", \"Label\"])\n",
    "\n",
    "objectsplit = 13\n",
    "upsamplingratio = 4\n",
    "layersPerObject = endlayer // objectsplit\n",
    "# Approximate one third test data\n",
    "testEnd = endlayer\n",
    "\n",
    "objectinfo.insert(1, \"VED\", objectinfo.P * 1000/(objectinfo.S * objectinfo.H * powderthickness))\n",
    "objectCoordinates = [[x, x+objectwidth, y, y+objectheight] for y in reversed(range(\n",
    "    ystart, yend, objectheight + yspacing)) for x in range(xstart, xend, xspacing + objectwidth)]\n",
    "coorddf = pd.DataFrame(objectCoordinates, columns=['xstart', 'xend', 'ystart', 'yend'])\n",
    "objectinfo = coorddf.join(objectinfo)\n",
    "objectinfo.drop(objectinfo[objectinfo.Label == 'KH'].index, inplace=True)\n",
    "objectinfo.replace('GOOD', 0, inplace=True)\n",
    "objectinfo.replace('LOF', 1, inplace=True)\n",
    "\n",
    "positive_multiplier = 1\n",
    "\n",
    "zs = [objectinfo.copy().assign(zstart=z, zend=z+layersPerObject) for z in range(0, testEnd-layersPerObject, layersPerObject//(upsamplingratio * positive_multiplier))]\n",
    "trainobjectinfo = pd.concat(zs, ignore_index=True)\n",
    "\n",
    "# This line removes all the lines from the dataframe that aren't created because of the positive_multiplier\n",
    "trainobjectinfo = trainobjectinfo[(trainobjectinfo['Label'] == 1) | (trainobjectinfo['zstart'] % (positive_multiplier) == 0)]\n",
    "\n",
    "trainobjectinfo.reset_index(drop=True, inplace=True)\n",
    "\n",
    "del zs\n",
    "del coorddf\n",
    "del objectCoordinates\n",
    "del objectinfo\n",
    "\n",
    "trainobjects = np.full((len(trainobjectinfo), layersPerObject, objectheight, objectwidth), np.nan)\n",
    "\n",
    "for index, object in trainobjectinfo.iterrows():\n",
    "    trainobjects[index] = integrals[object.zstart:object.zend, object.ystart:object.yend, object.xstart:object.xend]\n",
    "\n",
    "aggregate = np.sum(trainobjects, axis=(0,1))\n",
    "\n",
    "emptyRatio = 47\n",
    "limit = np.percentile(aggregate, emptyRatio)\n",
    "trainmask = aggregate >= limit\n",
    "trainmask = np.repeat([trainmask], layersPerObject, 0)\n",
    "del aggregate\n",
    "del limit\n",
    "del integrals\n",
    "# xs = np.copy(aggregate)\n",
    "# xs[~backgroundmask] = np.nan\n",
    "# plt.imshow(xs)\n",
    "# plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors, metrics\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime\n",
    "\n",
    "def preprocess(objects, type, sharpening, backgroundmask):\n",
    "    rtn = np.full(objects.shape, np.nan)\n",
    "    # print(rtn.shape)\n",
    "    for index, object in enumerate(objects):\n",
    "        sharpeningKernel = np.array([   [-1, -1,  -1],\n",
    "                                        [-1,  9,  -1],\n",
    "                                        [ -1, -1,  -1]\n",
    "        ]) if sharpening == 'diagonal' else np.array([  [0, -1,  0],\n",
    "                                                        [-1, 5, -1],\n",
    "                                                        [0, -1,  0]])\n",
    "        sharpened = np.array([cv2.filter2D(src=image, ddepth=-1, kernel=sharpeningKernel) for image in object])\n",
    "    # Sharpening is done\n",
    "        if type == 'scatter' or type == 'spatstat':\n",
    "            xs = np.array(sharpened, copy=True, dtype=np.float32)\n",
    "            (endLayer, _, _) = xs.shape\n",
    "            xs[~backgroundmask] = np.nan\n",
    "            rtn[index] = xs\n",
    "        elif type == 'moran':\n",
    "            xs = np.array(sharpened, copy=True, dtype=np.float32)\n",
    "            (endLayer, _, _) = xs.shape\n",
    "            avg = np.mean(xs, where=backgroundmask)\n",
    "            stddev = np.std(xs, where=backgroundmask)\n",
    "            xs = (xs - avg) / avg\n",
    "            xs[~backgroundmask] = np.nan\n",
    "            rtn[index] = xs\n",
    "    return rtn\n",
    "\n",
    "\n",
    "def calculateoutliers(objects, type, neighbourhoodSetting, windowSize):\n",
    "    c, z, y, x = objects.shape\n",
    "\n",
    "    outlierValues = np.full((c, z + 1 - windowSize, y, x), np.nan)\n",
    "    for index, object in enumerate(objects):\n",
    "        # Step 1: calculate neighbourhood\n",
    "        neighbourkernel = np.array(\n",
    "            [[1, 1, 1],\n",
    "            [1, 1, 1],\n",
    "            [1, 1, 1]]\n",
    "        )/9 if neighbourhoodSetting == 'grid' else np.array(\n",
    "            [[1, 2,  1],\n",
    "            [2, 4, 2],\n",
    "            [1, 2,  1]])/16\n",
    "        flatNeighbourhood = np.array([cv2.filter2D(src=layer, ddepth=-1, kernel=neighbourkernel) for layer in object])\n",
    "        neighbourhoodValues = np.array([\n",
    "            np.sum(flatNeighbourhood[layerIndex-windowSize:layerIndex], axis=0)/windowSize\n",
    "            for layerIndex in range(windowSize, z+1)\n",
    "        ])\n",
    "        # Step 2: calculate outlier\n",
    "        offset = windowSize // 2\n",
    "        endoffset = windowSize - offset - 1\n",
    "\n",
    "        xs = object[offset:z-endoffset]\n",
    "        ys = neighbourhoodValues[0:z-windowSize+1]\n",
    "        filter = np.logical_and(np.isfinite(xs), np.isfinite(ys))\n",
    "\n",
    "        assert(len(set(filter.flatten())) == 2)\n",
    "        if type == 'spatstat':\n",
    "            outliers = xs - ys\n",
    "            avg = np.mean(outliers[filter])\n",
    "            std = np.std(outliers[filter])\n",
    "            outliers = (outliers - avg) / std\n",
    "            outlierValues[index] = outliers\n",
    "        else:\n",
    "            # Is the axis right for moran/scatter?\n",
    "            # print(offset, endoffset, object.shape)\n",
    "            line = np.polyfit(ys[filter].flatten(), xs[filter].flatten(), 1)\n",
    "            p = np.poly1d(line)\n",
    "            outlierValues[index] = xs - p(ys)\n",
    "            assert(outlierValues[index].shape == xs.shape == p(ys).shape)\n",
    "        assert(len(np.unique(outlierValues[index])) > 1)\n",
    "        assert(len(np.unique(np.isfinite(outlierValues[index]))) == 2)\n",
    "    assert(np.average(np.isfinite(outlierValues)) > 0.4)\n",
    "    return outlierValues\n",
    "\n",
    "def encode(outlierobjects, type, buckets, histnormalise, minval=0, maxval=0):\n",
    "    numberOfObjects, _, _, _ = outlierobjects.shape\n",
    "    X = np.full((numberOfObjects, buckets), np.nan)\n",
    "    filter = np.isfinite(outlierobjects)\n",
    "    minval = np.min(outlierobjects[filter]) if minval == 0 else minval\n",
    "    maxval = np.max(outlierobjects[filter]) if maxval == 0 else maxval\n",
    "    for index in range(0, numberOfObjects):\n",
    "        xs = outlierobjects[index]\n",
    "        filter = np.isfinite(xs)\n",
    "        hist, _ = np.histogram(xs[filter], bins=buckets, range=(minval, maxval), density=True)\n",
    "        X[index] = np.array(hist)\n",
    "    \n",
    "    if (histnormalise == 'column'):\n",
    "        X = preprocessing.normalize(X, axis=0)\n",
    "    elif (histnormalise == 'row'):\n",
    "        X = preprocessing.normalize(X, axis=1)\n",
    "    return X, minval, maxval\n",
    "\n",
    "def classify(Xtrain, Ytrain, Xtest, Ytest, n_neighbors):\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=\"distance\")\n",
    "    cvscore = cross_val_score(clf, Xtrain, Ytrain, cv=5, scoring='roc_auc', n_jobs=-1).mean()\n",
    "    clf.fit(Xtrain, Ytrain)\n",
    "    yfit = clf.predict(Xtest)\n",
    "    return cvscore, metrics.roc_auc_score(Ytest, yfit), metrics.precision_score(Ytest, yfit, zero_division=0), metrics.recall_score(Ytest, yfit, zero_division=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweaking parameter settings\n",
    "types = ['moran', 'scatter', 'spatstat']\n",
    "sharpening = ['direct', 'diagonal']\n",
    "windowsizes = range(1, 6, 2)\n",
    "neighbourhoodSetting = ['grid', 'euclidean']\n",
    "buckets = range(30, 151, 30)\n",
    "histnormalise = ('none', 'row')\n",
    "#bucket-lower-limit?\n",
    "k = range(2, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:14:35 Processing type:  moran  sharpening:  direct\n",
      "00:14:38 Processing windowSize:  1  neighbourhood:  grid\n",
      "00:15:47 Processing windowSize:  1  neighbourhood:  euclidean\n",
      "00:16:48 Processing windowSize:  3  neighbourhood:  grid\n",
      "00:17:41 Processing windowSize:  3  neighbourhood:  euclidean\n"
     ]
    }
   ],
   "source": [
    "# Now to tie it all together...\n",
    "columns = ['type', 'sharpening', 'windowSize', 'neighbourhood', 'buckets', 'histnormalise', 'k-nearest', 'cv-auc', 'test-auc', 'test-precision', 'test-recall']\n",
    "results = pd.DataFrame(columns=columns)\n",
    "Ytrain = np.array(trainobjectinfo.loc[:,\"Label\"])\n",
    "Ytest = np.array(testobjectinfo.loc[:,\"Label\"])\n",
    "for type in types:\n",
    "    for sharpSetting in sharpening:\n",
    "        print(datetime.now().strftime(\"%H:%M:%S\"), \"Processing type: \", type, \" sharpening: \", sharpSetting)\n",
    "        # trainpreprocessed = np.apply_along_axis(preprocess, 1, trainobjects, type, sharpSetting)\n",
    "        trainpreprocessed =preprocess(trainobjects, type, sharpSetting, trainmask)\n",
    "        testpreprocessed =preprocess(testobjects, type, sharpSetting, testmask)\n",
    "        for windowsize in windowsizes:\n",
    "            for nSetting in neighbourhoodSetting:\n",
    "                print(datetime.now().strftime(\"%H:%M:%S\"), \"Processing windowSize: \", windowsize, \" neighbourhood: \", nSetting)\n",
    "                # trainoutliers = np.apply_along_axis(calculateoutliers, 1, trainpreprocessed, type, nSetting, windowsize)\n",
    "                trainoutliers = calculateoutliers(trainpreprocessed, type, nSetting, windowsize)\n",
    "                testoutliers = calculateoutliers(testpreprocessed, type, nSetting, windowsize)\n",
    "                for histnorm in histnormalise:\n",
    "                    for bucket in buckets:\n",
    "                        Xtrain, minval, maxval = encode(trainoutliers, type, bucket, histnorm)\n",
    "                        Xtest, _, _ = encode(testoutliers, type, bucket, histnorm, minval=minval, maxval=maxval)\n",
    "                        # Add encode for test as well\n",
    "                        for n_neighbors in k:\n",
    "                            cvscore, score, precision, recall = classify(Xtrain, Ytrain, Xtest, Ytest, n_neighbors)\n",
    "                            nextRow =  pd.DataFrame([[type, sharpSetting, windowsize, nSetting, bucket, histnorm, n_neighbors, cvscore, score, precision, recall]], columns=columns)\n",
    "                            results = pd.concat([results, nextRow])\n",
    "                        results.to_csv('out14.csv', index=False, header=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('thesis-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b582782fd74adb665333939d2eb8c9995c52902e0db289bedb880e3a83e2d4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
